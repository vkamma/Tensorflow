{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "tensor-flow-2-1",
      "graded_item_id": "mtZ4n",
      "launcher_item_id": "WphgK"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Week 3 Programming Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkamma/Tensorflow/blob/main/Week_3_Programming_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crtnb3v_-QN8"
      },
      "source": [
        "# Programming Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5lhOgL2-QN9"
      },
      "source": [
        "## Model validation on the Iris dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mu5pYMU-QN-"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "In this notebook, you will build, compile and fit a neural network model to the Iris dataset. You will also implement validation, regularisation and callbacks to improve your model.\n",
        "\n",
        "Some code cells are provided you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line: \n",
        "\n",
        "`#### GRADED CELL ####`\n",
        "\n",
        "Don't move or edit this first line - this is what the automatic grader looks for to recognise graded cells. These cells require you to write your own code to complete them, and are automatically graded when you submit the notebook. Don't edit the function name or signature provided in these cells, otherwise the automatic grader might not function properly. Inside these graded cells, you can use any functions or classes that are imported below, but make sure you don't use any variables that are outside the scope of the function.\n",
        "\n",
        "### How to submit\n",
        "\n",
        "Complete all the tasks you are asked for in the worksheet. When you have finished and are happy with your code, press the **Submit Assignment** button at the top of this notebook.\n",
        "\n",
        "### Let's get started!\n",
        "\n",
        "We'll start running some imports, and loading the dataset. Do not edit the existing imports in the following cell. If you would like to make further Tensorflow imports, you should add them here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcJ88o-A-QOA"
      },
      "source": [
        "#### PACKAGE IMPORTS ####\n",
        "\n",
        "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
        "from numpy.random import seed\n",
        "seed(8)\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, model_selection \n",
        "%matplotlib inline\n",
        "\n",
        "# If you would like to make further imports from tensorflow, add them here\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
        "from tensorflow.keras.initializers import he_uniform"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVxBqpU_-QOF"
      },
      "source": [
        "#### The Iris dataset\n",
        "\n",
        "In this assignment, you will use the [Iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html). It consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters. For a reference, see the following papers:\n",
        "\n",
        "- R. A. Fisher. \"The use of multiple measurements in taxonomic problems\". Annals of Eugenics. 7 (2): 179â€“188, 1936.\n",
        "\n",
        "Your goal is to construct a neural network that classifies each sample into the correct class, as well as applying validation and regularisation techniques."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcDc7CXG-QOG"
      },
      "source": [
        "#### Load and preprocess the data\n",
        "\n",
        "First read in the Iris dataset using `datasets.load_iris()`, and split the dataset into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QCdzIiC-QOH"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def read_in_and_split_data(iris_data):\n",
        "    \"\"\"\n",
        "    This function takes the Iris dataset as loaded by sklearn.datasets.load_iris(), and then \n",
        "    splits so that the training set includes 90% of the full dataset, with the test set \n",
        "    making up the remaining 10%.\n",
        "    Your function should return a tuple (train_data, test_data, train_targets, test_targets) \n",
        "    of appropriately split training and test data and targets.\n",
        "    \n",
        "    If you would like to import any further packages to aid you in this task, please do so in the \n",
        "    Package Imports cell above.\n",
        "    \"\"\"\n",
        "    return model_selection.train_test_split(iris_data['data'], iris_data['target'], test_size=0.1)    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVTDnj1W-QOJ"
      },
      "source": [
        "# Run your function to generate the test and training data.\n",
        "\n",
        "iris_data = datasets.load_iris()\n",
        "train_data, test_data, train_targets, test_targets = read_in_and_split_data(iris_data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i_TGqos-QON"
      },
      "source": [
        "We will now convert the training and test targets using a one hot encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uolvGsLl-QOO"
      },
      "source": [
        "# Convert targets to a one-hot encoding\n",
        "\n",
        "train_targets = tf.keras.utils.to_categorical(np.array(train_targets))\n",
        "test_targets = tf.keras.utils.to_categorical(np.array(test_targets))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6i8xjbh-QOR"
      },
      "source": [
        "#### Build the neural network model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDQeTk4u-QOT"
      },
      "source": [
        "You can now construct a model to fit to the data. Using the Sequential API, build your model according to the following specifications:\n",
        "\n",
        "* The model should use the `input_shape` in the function argument to set the input size in the first layer.\n",
        "* The first layer should be a dense layer with 64 units.\n",
        "* The weights of the first layer should be initialised with the He uniform initializer.\n",
        "* The biases of the first layer should be all initially equal to one.\n",
        "* There should then be a further four dense layers, each with 128 units.\n",
        "* This should be followed with four dense layers, each with 64 units.\n",
        "* All of these Dense layers should use the ReLU activation function.\n",
        "* The output Dense layer should have 3 units and the softmax activation function.\n",
        "\n",
        "In total, the network should have 10 layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOCmCe2l-QOU"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_model(input_shape):\n",
        "    \"\"\"\n",
        "    This function should build a Sequential model according to the above specification. Ensure the \n",
        "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument.\n",
        "    Your function should return the model.\n",
        "    \"\"\"\n",
        "    model =  Sequential([\n",
        "                         Dense(64, activation='relu', input_shape=input_shape, kernel_initializer=he_uniform, bias_initializer='ones'),\n",
        "                         Dense(128, activation='relu'),\n",
        "                         Dense(128, activation='relu'),\n",
        "                         Dense(128, activation='relu'),\n",
        "                         Dense(128, activation='relu'),\n",
        "                         Dense(64, activation='relu'),\n",
        "                         Dense(64, activation='relu'),\n",
        "                         Dense(64, activation='relu'),\n",
        "                         Dense(64, activation='relu'),\n",
        "                         Dense(3, activation='softmax')\n",
        "    ])\n",
        "    return model    "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEnEugVV-QOX"
      },
      "source": [
        "# Run your function to get the model\n",
        "\n",
        "model = get_model(train_data[0].shape)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC0h-ud1-QOa"
      },
      "source": [
        "#### Compile the model\n",
        "\n",
        "You should now compile the model using the `compile` method. Remember that you need to specify an optimizer, a loss function and a metric to judge the performance of your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReHF4llc-QOa"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def compile_model(model):\n",
        "    \"\"\"\n",
        "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
        "    loss function and metric.\n",
        "    Compile the model using the Adam optimiser (with learning rate set to 0.0001), \n",
        "    the categorical crossentropy loss function and accuracy as the only metric. \n",
        "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
        "    \"\"\"\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy']\n",
        "                  )    "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qJOJunW-QOd"
      },
      "source": [
        "# Run your function to compile the model\n",
        "\n",
        "compile_model(model)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWxL16Hk-QOh"
      },
      "source": [
        "#### Fit the model to the training data\n",
        "\n",
        "Now you should train the model on the Iris dataset, using the model's `fit` method. \n",
        "* Run the training for a fixed number of epochs, given by the function's `epochs` argument.\n",
        "* Return the training history to be used for plotting the learning curves.\n",
        "* Set the batch size to 40.\n",
        "* Set the validation set to be 15% of the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYTwJVXq-QOi"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def train_model(model, train_data, train_targets, epochs):\n",
        "    \"\"\"\n",
        "    This function should train the model for the given number of epochs on the \n",
        "    train_data and train_targets. \n",
        "    Your function should return the training history, as returned by model.fit.\n",
        "    \"\"\"\n",
        "    history = model.fit(train_data, train_targets, epochs=epochs, validation_split=0.15, batch_size=40)\n",
        "    return history"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOE4iz_w-QOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11ce6eba-1e04-44c3-ce47-aa2dbca85726"
      },
      "source": [
        "# Run your function to train the model\n",
        "\n",
        "history = train_model(model, train_data, train_targets, epochs=800)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/800\n",
            "3/3 [==============================] - 1s 107ms/step - loss: 1.0454 - accuracy: 0.3333 - val_loss: 0.9058 - val_accuracy: 0.5714\n",
            "Epoch 2/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8420 - accuracy: 0.6579 - val_loss: 0.7176 - val_accuracy: 0.6190\n",
            "Epoch 3/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6444 - accuracy: 0.7456 - val_loss: 0.5044 - val_accuracy: 0.9048\n",
            "Epoch 4/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.4450 - accuracy: 0.8947 - val_loss: 0.3397 - val_accuracy: 0.9524\n",
            "Epoch 5/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2998 - accuracy: 0.9474 - val_loss: 0.2698 - val_accuracy: 0.9524\n",
            "Epoch 6/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2598 - accuracy: 0.8860 - val_loss: 0.2448 - val_accuracy: 0.9048\n",
            "Epoch 7/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1757 - accuracy: 0.9737 - val_loss: 0.1635 - val_accuracy: 0.9524\n",
            "Epoch 8/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1653 - accuracy: 0.9474 - val_loss: 0.1584 - val_accuracy: 0.9048\n",
            "Epoch 9/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1139 - accuracy: 0.9825 - val_loss: 0.1145 - val_accuracy: 0.9524\n",
            "Epoch 10/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1105 - accuracy: 0.9649 - val_loss: 0.1143 - val_accuracy: 0.9524\n",
            "Epoch 11/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1075 - accuracy: 0.9474 - val_loss: 0.1352 - val_accuracy: 0.9524\n",
            "Epoch 12/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0911 - accuracy: 0.9649 - val_loss: 0.1768 - val_accuracy: 0.9048\n",
            "Epoch 13/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2013 - accuracy: 0.9123 - val_loss: 0.1881 - val_accuracy: 0.9048\n",
            "Epoch 14/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1601 - accuracy: 0.9298 - val_loss: 0.1099 - val_accuracy: 0.9524\n",
            "Epoch 15/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1660 - accuracy: 0.9386 - val_loss: 0.0954 - val_accuracy: 0.9524\n",
            "Epoch 16/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1880 - accuracy: 0.9474 - val_loss: 0.0899 - val_accuracy: 0.9524\n",
            "Epoch 17/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0885 - accuracy: 0.9737 - val_loss: 0.3402 - val_accuracy: 0.9048\n",
            "Epoch 18/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1398 - accuracy: 0.9386 - val_loss: 0.1344 - val_accuracy: 0.9524\n",
            "Epoch 19/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1562 - accuracy: 0.9298 - val_loss: 0.1410 - val_accuracy: 0.9524\n",
            "Epoch 20/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1331 - accuracy: 0.9561 - val_loss: 0.1593 - val_accuracy: 0.9048\n",
            "Epoch 21/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1007 - accuracy: 0.9561 - val_loss: 0.1181 - val_accuracy: 0.9524\n",
            "Epoch 22/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1137 - accuracy: 0.9474 - val_loss: 0.1558 - val_accuracy: 0.9048\n",
            "Epoch 23/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0980 - accuracy: 0.9737 - val_loss: 0.1000 - val_accuracy: 0.9524\n",
            "Epoch 24/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0903 - accuracy: 0.9474 - val_loss: 0.0971 - val_accuracy: 0.9524\n",
            "Epoch 25/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0774 - accuracy: 0.9737 - val_loss: 0.1495 - val_accuracy: 0.9524\n",
            "Epoch 26/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0805 - accuracy: 0.9737 - val_loss: 0.0862 - val_accuracy: 0.9524\n",
            "Epoch 27/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0992 - accuracy: 0.9474 - val_loss: 0.1081 - val_accuracy: 0.9524\n",
            "Epoch 28/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 0.1100 - val_accuracy: 0.9524\n",
            "Epoch 29/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0697 - accuracy: 0.9737 - val_loss: 0.0798 - val_accuracy: 0.9524\n",
            "Epoch 30/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1176 - accuracy: 0.9649 - val_loss: 0.1721 - val_accuracy: 0.9048\n",
            "Epoch 31/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1493 - accuracy: 0.9474 - val_loss: 0.1571 - val_accuracy: 0.9048\n",
            "Epoch 32/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0912 - accuracy: 0.9649 - val_loss: 0.0918 - val_accuracy: 0.9524\n",
            "Epoch 33/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0776 - accuracy: 0.9649 - val_loss: 0.1583 - val_accuracy: 0.9048\n",
            "Epoch 34/800\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.1133 - accuracy: 0.9649 - val_loss: 0.1165 - val_accuracy: 0.9524\n",
            "Epoch 35/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1246 - accuracy: 0.9211 - val_loss: 0.1197 - val_accuracy: 0.9524\n",
            "Epoch 36/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0729 - accuracy: 0.9737 - val_loss: 0.1499 - val_accuracy: 0.9048\n",
            "Epoch 37/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0847 - accuracy: 0.9737 - val_loss: 0.0956 - val_accuracy: 0.9524\n",
            "Epoch 38/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0772 - accuracy: 0.9737 - val_loss: 0.1057 - val_accuracy: 0.9524\n",
            "Epoch 39/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0739 - accuracy: 0.9737 - val_loss: 0.1427 - val_accuracy: 0.9524\n",
            "Epoch 40/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0736 - accuracy: 0.9737 - val_loss: 0.0898 - val_accuracy: 0.9524\n",
            "Epoch 41/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0768 - accuracy: 0.9561 - val_loss: 0.1112 - val_accuracy: 0.9524\n",
            "Epoch 42/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9737 - val_loss: 0.1249 - val_accuracy: 0.9524\n",
            "Epoch 43/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0894 - accuracy: 0.9561 - val_loss: 0.1033 - val_accuracy: 0.9524\n",
            "Epoch 44/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0729 - accuracy: 0.9737 - val_loss: 0.1512 - val_accuracy: 0.9048\n",
            "Epoch 45/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 0.0908 - val_accuracy: 0.9524\n",
            "Epoch 46/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0662 - accuracy: 0.9825 - val_loss: 0.0974 - val_accuracy: 0.9524\n",
            "Epoch 47/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0635 - accuracy: 0.9737 - val_loss: 0.1100 - val_accuracy: 0.9524\n",
            "Epoch 48/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0630 - accuracy: 0.9737 - val_loss: 0.0877 - val_accuracy: 0.9524\n",
            "Epoch 49/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0623 - accuracy: 0.9825 - val_loss: 0.1032 - val_accuracy: 0.9524\n",
            "Epoch 50/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0628 - accuracy: 0.9825 - val_loss: 0.1256 - val_accuracy: 0.9524\n",
            "Epoch 51/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0677 - accuracy: 0.9737 - val_loss: 0.1146 - val_accuracy: 0.9524\n",
            "Epoch 52/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0621 - accuracy: 0.9825 - val_loss: 0.0874 - val_accuracy: 0.9524\n",
            "Epoch 53/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0712 - accuracy: 0.9825 - val_loss: 0.1265 - val_accuracy: 0.9524\n",
            "Epoch 54/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0845 - accuracy: 0.9474 - val_loss: 0.1113 - val_accuracy: 0.9524\n",
            "Epoch 55/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0698 - accuracy: 0.9737 - val_loss: 0.1527 - val_accuracy: 0.9048\n",
            "Epoch 56/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0789 - accuracy: 0.9649 - val_loss: 0.0810 - val_accuracy: 0.9524\n",
            "Epoch 57/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0624 - accuracy: 0.9825 - val_loss: 0.1284 - val_accuracy: 0.9524\n",
            "Epoch 58/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0760 - accuracy: 0.9737 - val_loss: 0.1239 - val_accuracy: 0.9524\n",
            "Epoch 59/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0599 - accuracy: 0.9737 - val_loss: 0.0749 - val_accuracy: 0.9524\n",
            "Epoch 60/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0661 - accuracy: 0.9737 - val_loss: 0.1336 - val_accuracy: 0.9524\n",
            "Epoch 61/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0686 - accuracy: 0.9737 - val_loss: 0.0825 - val_accuracy: 0.9524\n",
            "Epoch 62/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0659 - accuracy: 0.9825 - val_loss: 0.1483 - val_accuracy: 0.9048\n",
            "Epoch 63/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1022 - accuracy: 0.9649 - val_loss: 0.1909 - val_accuracy: 0.9048\n",
            "Epoch 64/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0792 - accuracy: 0.9561 - val_loss: 0.0628 - val_accuracy: 1.0000\n",
            "Epoch 65/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0635 - accuracy: 0.9825 - val_loss: 0.1134 - val_accuracy: 0.9524\n",
            "Epoch 66/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0731 - accuracy: 0.9737 - val_loss: 0.1143 - val_accuracy: 0.9524\n",
            "Epoch 67/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0648 - accuracy: 0.9737 - val_loss: 0.0701 - val_accuracy: 0.9524\n",
            "Epoch 68/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0694 - accuracy: 0.9737 - val_loss: 0.1870 - val_accuracy: 0.9048\n",
            "Epoch 69/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0842 - accuracy: 0.9737 - val_loss: 0.1009 - val_accuracy: 0.9524\n",
            "Epoch 70/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0559 - accuracy: 0.9825 - val_loss: 0.0684 - val_accuracy: 0.9524\n",
            "Epoch 71/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0674 - accuracy: 0.9737 - val_loss: 0.1141 - val_accuracy: 0.9524\n",
            "Epoch 72/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0714 - accuracy: 0.9737 - val_loss: 0.0968 - val_accuracy: 0.9524\n",
            "Epoch 73/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0616 - accuracy: 0.9737 - val_loss: 0.1022 - val_accuracy: 0.9524\n",
            "Epoch 74/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0614 - accuracy: 0.9737 - val_loss: 0.0949 - val_accuracy: 0.9524\n",
            "Epoch 75/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 0.0931 - val_accuracy: 0.9524\n",
            "Epoch 76/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0694 - accuracy: 0.9649 - val_loss: 0.1611 - val_accuracy: 0.9048\n",
            "Epoch 77/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0690 - accuracy: 0.9737 - val_loss: 0.0703 - val_accuracy: 0.9524\n",
            "Epoch 78/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0653 - accuracy: 0.9737 - val_loss: 0.2309 - val_accuracy: 0.9048\n",
            "Epoch 79/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1124 - accuracy: 0.9561 - val_loss: 0.1081 - val_accuracy: 0.9524\n",
            "Epoch 80/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0979 - accuracy: 0.9474 - val_loss: 0.1135 - val_accuracy: 0.9524\n",
            "Epoch 81/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0779 - accuracy: 0.9737 - val_loss: 0.1859 - val_accuracy: 0.9048\n",
            "Epoch 82/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0924 - accuracy: 0.9737 - val_loss: 0.0876 - val_accuracy: 1.0000\n",
            "Epoch 83/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0783 - accuracy: 0.9825 - val_loss: 0.1221 - val_accuracy: 0.9524\n",
            "Epoch 84/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0643 - accuracy: 0.9737 - val_loss: 0.1260 - val_accuracy: 0.9524\n",
            "Epoch 85/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0620 - accuracy: 0.9737 - val_loss: 0.0737 - val_accuracy: 0.9524\n",
            "Epoch 86/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.9649 - val_loss: 0.1032 - val_accuracy: 0.9524\n",
            "Epoch 87/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0639 - accuracy: 0.9737 - val_loss: 0.1149 - val_accuracy: 0.9524\n",
            "Epoch 88/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0539 - accuracy: 0.9825 - val_loss: 0.0631 - val_accuracy: 0.9524\n",
            "Epoch 89/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0759 - accuracy: 0.9737 - val_loss: 0.1861 - val_accuracy: 0.9048\n",
            "Epoch 90/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0695 - accuracy: 0.9737 - val_loss: 0.0724 - val_accuracy: 0.9524\n",
            "Epoch 91/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0610 - accuracy: 0.9825 - val_loss: 0.0605 - val_accuracy: 0.9524\n",
            "Epoch 92/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0916 - accuracy: 0.9737 - val_loss: 0.2291 - val_accuracy: 0.9048\n",
            "Epoch 93/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0761 - accuracy: 0.9737 - val_loss: 0.0591 - val_accuracy: 1.0000\n",
            "Epoch 94/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0726 - accuracy: 0.9737 - val_loss: 0.1280 - val_accuracy: 0.9524\n",
            "Epoch 95/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0711 - accuracy: 0.9737 - val_loss: 0.1490 - val_accuracy: 0.9048\n",
            "Epoch 96/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0770 - accuracy: 0.9737 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
            "Epoch 97/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0653 - accuracy: 0.9825 - val_loss: 0.1530 - val_accuracy: 0.9048\n",
            "Epoch 98/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0822 - accuracy: 0.9737 - val_loss: 0.1559 - val_accuracy: 0.9048\n",
            "Epoch 99/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0624 - accuracy: 0.9649 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
            "Epoch 100/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1103 - accuracy: 0.9649 - val_loss: 0.2286 - val_accuracy: 0.9048\n",
            "Epoch 101/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0881 - accuracy: 0.9737 - val_loss: 0.0670 - val_accuracy: 0.9524\n",
            "Epoch 102/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0728 - accuracy: 0.9649 - val_loss: 0.1737 - val_accuracy: 0.9048\n",
            "Epoch 103/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0926 - accuracy: 0.9561 - val_loss: 0.1879 - val_accuracy: 0.9048\n",
            "Epoch 104/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0744 - accuracy: 0.9737 - val_loss: 0.0725 - val_accuracy: 0.9524\n",
            "Epoch 105/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0904 - accuracy: 0.9737 - val_loss: 0.1959 - val_accuracy: 0.9048\n",
            "Epoch 106/800\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.1256 - accuracy: 0.9474 - val_loss: 0.1912 - val_accuracy: 0.9048\n",
            "Epoch 107/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1112 - accuracy: 0.9649 - val_loss: 0.0971 - val_accuracy: 0.9524\n",
            "Epoch 108/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1064 - accuracy: 0.9561 - val_loss: 0.2039 - val_accuracy: 0.9048\n",
            "Epoch 109/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1616 - accuracy: 0.9123 - val_loss: 0.1530 - val_accuracy: 0.9048\n",
            "Epoch 110/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0776 - accuracy: 0.9649 - val_loss: 0.1019 - val_accuracy: 0.9524\n",
            "Epoch 111/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0910 - accuracy: 0.9737 - val_loss: 0.1462 - val_accuracy: 0.9048\n",
            "Epoch 112/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0836 - accuracy: 0.9737 - val_loss: 0.1655 - val_accuracy: 0.9048\n",
            "Epoch 113/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0726 - accuracy: 0.9737 - val_loss: 0.0789 - val_accuracy: 0.9524\n",
            "Epoch 114/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0667 - accuracy: 0.9825 - val_loss: 0.0731 - val_accuracy: 0.9524\n",
            "Epoch 115/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0599 - accuracy: 0.9737 - val_loss: 0.0987 - val_accuracy: 0.9524\n",
            "Epoch 116/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0580 - accuracy: 0.9737 - val_loss: 0.0853 - val_accuracy: 0.9524\n",
            "Epoch 117/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0620 - accuracy: 0.9737 - val_loss: 0.0605 - val_accuracy: 0.9524\n",
            "Epoch 118/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0565 - accuracy: 0.9825 - val_loss: 0.0894 - val_accuracy: 0.9524\n",
            "Epoch 119/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0721 - accuracy: 0.9737 - val_loss: 0.1273 - val_accuracy: 0.9524\n",
            "Epoch 120/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0635 - accuracy: 0.9737 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
            "Epoch 121/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0673 - accuracy: 0.9737 - val_loss: 0.1768 - val_accuracy: 0.9048\n",
            "Epoch 122/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0800 - accuracy: 0.9737 - val_loss: 0.1614 - val_accuracy: 0.9048\n",
            "Epoch 123/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0610 - accuracy: 0.9737 - val_loss: 0.0638 - val_accuracy: 0.9524\n",
            "Epoch 124/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0779 - accuracy: 0.9649 - val_loss: 0.1585 - val_accuracy: 0.9048\n",
            "Epoch 125/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0779 - accuracy: 0.9737 - val_loss: 0.1661 - val_accuracy: 0.9048\n",
            "Epoch 126/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0655 - accuracy: 0.9737 - val_loss: 0.0734 - val_accuracy: 0.9524\n",
            "Epoch 127/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0657 - accuracy: 0.9825 - val_loss: 0.0841 - val_accuracy: 0.9524\n",
            "Epoch 128/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.0915 - val_accuracy: 0.9524\n",
            "Epoch 129/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0547 - accuracy: 0.9825 - val_loss: 0.0946 - val_accuracy: 0.9524\n",
            "Epoch 130/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0528 - accuracy: 0.9737 - val_loss: 0.0857 - val_accuracy: 0.9524\n",
            "Epoch 131/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0653 - accuracy: 0.9737 - val_loss: 0.0964 - val_accuracy: 0.9524\n",
            "Epoch 132/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0883 - accuracy: 0.9649 - val_loss: 0.1502 - val_accuracy: 0.9048\n",
            "Epoch 133/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0779 - accuracy: 0.9737 - val_loss: 0.2738 - val_accuracy: 0.9048\n",
            "Epoch 134/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0933 - accuracy: 0.9737 - val_loss: 0.0804 - val_accuracy: 0.9524\n",
            "Epoch 135/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0714 - accuracy: 0.9825 - val_loss: 0.0746 - val_accuracy: 0.9524\n",
            "Epoch 136/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0599 - accuracy: 0.9737 - val_loss: 0.1190 - val_accuracy: 0.9524\n",
            "Epoch 137/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0586 - accuracy: 0.9737 - val_loss: 0.1028 - val_accuracy: 0.9524\n",
            "Epoch 138/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0554 - accuracy: 0.9825 - val_loss: 0.0693 - val_accuracy: 0.9524\n",
            "Epoch 139/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0663 - accuracy: 0.9737 - val_loss: 0.1089 - val_accuracy: 0.9524\n",
            "Epoch 140/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 0.0799 - val_accuracy: 0.9524\n",
            "Epoch 141/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0547 - accuracy: 0.9825 - val_loss: 0.1011 - val_accuracy: 0.9524\n",
            "Epoch 142/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0612 - accuracy: 0.9825 - val_loss: 0.1581 - val_accuracy: 0.9048\n",
            "Epoch 143/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0562 - accuracy: 0.9737 - val_loss: 0.0567 - val_accuracy: 0.9524\n",
            "Epoch 144/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0656 - accuracy: 0.9737 - val_loss: 0.1277 - val_accuracy: 0.9524\n",
            "Epoch 145/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0873 - accuracy: 0.9737 - val_loss: 0.2423 - val_accuracy: 0.9048\n",
            "Epoch 146/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0841 - accuracy: 0.9737 - val_loss: 0.0835 - val_accuracy: 0.9524\n",
            "Epoch 147/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.0668 - val_accuracy: 0.9524\n",
            "Epoch 148/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0602 - accuracy: 0.9825 - val_loss: 0.1745 - val_accuracy: 0.9048\n",
            "Epoch 149/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0718 - accuracy: 0.9737 - val_loss: 0.1774 - val_accuracy: 0.9048\n",
            "Epoch 150/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0617 - accuracy: 0.9737 - val_loss: 0.0947 - val_accuracy: 0.9524\n",
            "Epoch 151/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0606 - accuracy: 0.9825 - val_loss: 0.0803 - val_accuracy: 0.9524\n",
            "Epoch 152/800\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0647 - accuracy: 0.9649 - val_loss: 0.1751 - val_accuracy: 0.9048\n",
            "Epoch 153/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0677 - accuracy: 0.9737 - val_loss: 0.1617 - val_accuracy: 0.9048\n",
            "Epoch 154/800\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0578 - accuracy: 0.9737 - val_loss: 0.1029 - val_accuracy: 0.9524\n",
            "Epoch 155/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0540 - accuracy: 0.9825 - val_loss: 0.0650 - val_accuracy: 0.9524\n",
            "Epoch 156/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0587 - accuracy: 0.9825 - val_loss: 0.1347 - val_accuracy: 0.9048\n",
            "Epoch 157/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0616 - accuracy: 0.9737 - val_loss: 0.1548 - val_accuracy: 0.9048\n",
            "Epoch 158/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0607 - accuracy: 0.9737 - val_loss: 0.1092 - val_accuracy: 0.9524\n",
            "Epoch 159/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0919 - accuracy: 0.9649 - val_loss: 0.1147 - val_accuracy: 0.9048\n",
            "Epoch 160/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0960 - accuracy: 0.9649 - val_loss: 0.2102 - val_accuracy: 0.9048\n",
            "Epoch 161/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0670 - accuracy: 0.9737 - val_loss: 0.0758 - val_accuracy: 0.9524\n",
            "Epoch 162/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1141 - accuracy: 0.9474 - val_loss: 0.1127 - val_accuracy: 0.9048\n",
            "Epoch 163/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0829 - accuracy: 0.9737 - val_loss: 0.2620 - val_accuracy: 0.9048\n",
            "Epoch 164/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1545 - accuracy: 0.9211 - val_loss: 0.1101 - val_accuracy: 0.9524\n",
            "Epoch 165/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0896 - accuracy: 0.9737 - val_loss: 0.0990 - val_accuracy: 0.9524\n",
            "Epoch 166/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1223 - accuracy: 0.9561 - val_loss: 0.2063 - val_accuracy: 0.9048\n",
            "Epoch 167/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1233 - accuracy: 0.9386 - val_loss: 0.1646 - val_accuracy: 0.9048\n",
            "Epoch 168/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0918 - accuracy: 0.9561 - val_loss: 0.0945 - val_accuracy: 0.9524\n",
            "Epoch 169/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.1080 - accuracy: 0.9561 - val_loss: 0.1432 - val_accuracy: 0.9048\n",
            "Epoch 170/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0913 - accuracy: 0.9649 - val_loss: 0.2559 - val_accuracy: 0.9048\n",
            "Epoch 171/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1089 - accuracy: 0.9474 - val_loss: 0.1293 - val_accuracy: 0.9048\n",
            "Epoch 172/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0554 - accuracy: 0.9825 - val_loss: 0.0719 - val_accuracy: 0.9524\n",
            "Epoch 173/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0769 - accuracy: 0.9737 - val_loss: 0.1118 - val_accuracy: 0.9524\n",
            "Epoch 174/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0696 - accuracy: 0.9737 - val_loss: 0.1713 - val_accuracy: 0.9048\n",
            "Epoch 175/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0660 - accuracy: 0.9737 - val_loss: 0.1525 - val_accuracy: 0.9048\n",
            "Epoch 176/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0625 - accuracy: 0.9737 - val_loss: 0.0966 - val_accuracy: 0.9524\n",
            "Epoch 177/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0528 - accuracy: 0.9825 - val_loss: 0.0667 - val_accuracy: 0.9524\n",
            "Epoch 178/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0707 - accuracy: 0.9825 - val_loss: 0.0731 - val_accuracy: 0.9524\n",
            "Epoch 179/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0579 - accuracy: 0.9737 - val_loss: 0.1808 - val_accuracy: 0.9048\n",
            "Epoch 180/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0729 - accuracy: 0.9737 - val_loss: 0.1633 - val_accuracy: 0.9048\n",
            "Epoch 181/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0643 - accuracy: 0.9737 - val_loss: 0.1088 - val_accuracy: 0.9524\n",
            "Epoch 182/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0589 - accuracy: 0.9737 - val_loss: 0.0735 - val_accuracy: 0.9524\n",
            "Epoch 183/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0565 - accuracy: 0.9912 - val_loss: 0.1018 - val_accuracy: 0.9524\n",
            "Epoch 184/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0552 - accuracy: 0.9825 - val_loss: 0.1193 - val_accuracy: 0.9048\n",
            "Epoch 185/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0575 - accuracy: 0.9737 - val_loss: 0.1100 - val_accuracy: 0.9524\n",
            "Epoch 186/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 0.9737 - val_loss: 0.0657 - val_accuracy: 0.9524\n",
            "Epoch 187/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0542 - accuracy: 0.9737 - val_loss: 0.1095 - val_accuracy: 0.9524\n",
            "Epoch 188/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0520 - accuracy: 0.9825 - val_loss: 0.1004 - val_accuracy: 0.9524\n",
            "Epoch 189/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0506 - accuracy: 0.9737 - val_loss: 0.0654 - val_accuracy: 0.9524\n",
            "Epoch 190/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0504 - accuracy: 0.9825 - val_loss: 0.0839 - val_accuracy: 0.9524\n",
            "Epoch 191/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0626 - accuracy: 0.9737 - val_loss: 0.0840 - val_accuracy: 0.9524\n",
            "Epoch 192/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0697 - accuracy: 0.9737 - val_loss: 0.1793 - val_accuracy: 0.9048\n",
            "Epoch 193/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0678 - accuracy: 0.9737 - val_loss: 0.1163 - val_accuracy: 0.9048\n",
            "Epoch 194/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0522 - accuracy: 0.9825 - val_loss: 0.0820 - val_accuracy: 0.9524\n",
            "Epoch 195/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0708 - accuracy: 0.9737 - val_loss: 0.0769 - val_accuracy: 0.9524\n",
            "Epoch 196/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0523 - accuracy: 0.9825 - val_loss: 0.1227 - val_accuracy: 0.9048\n",
            "Epoch 197/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0542 - accuracy: 0.9825 - val_loss: 0.1295 - val_accuracy: 0.9048\n",
            "Epoch 198/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0521 - accuracy: 0.9825 - val_loss: 0.0630 - val_accuracy: 0.9524\n",
            "Epoch 199/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0537 - accuracy: 0.9737 - val_loss: 0.0786 - val_accuracy: 0.9524\n",
            "Epoch 200/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0487 - accuracy: 0.9825 - val_loss: 0.0704 - val_accuracy: 0.9524\n",
            "Epoch 201/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 0.1197 - val_accuracy: 0.9524\n",
            "Epoch 202/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0640 - accuracy: 0.9737 - val_loss: 0.0991 - val_accuracy: 0.9524\n",
            "Epoch 203/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 0.1457 - val_accuracy: 0.9048\n",
            "Epoch 204/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0593 - accuracy: 0.9825 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
            "Epoch 205/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0538 - accuracy: 0.9825 - val_loss: 0.0854 - val_accuracy: 0.9524\n",
            "Epoch 206/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.1395 - val_accuracy: 0.9048\n",
            "Epoch 207/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0624 - accuracy: 0.9737 - val_loss: 0.1369 - val_accuracy: 0.9048\n",
            "Epoch 208/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.0390 - val_accuracy: 1.0000\n",
            "Epoch 209/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0647 - accuracy: 0.9825 - val_loss: 0.1595 - val_accuracy: 0.9048\n",
            "Epoch 210/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0716 - accuracy: 0.9737 - val_loss: 0.2235 - val_accuracy: 0.9048\n",
            "Epoch 211/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0735 - accuracy: 0.9737 - val_loss: 0.1079 - val_accuracy: 0.9524\n",
            "Epoch 212/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0879 - accuracy: 0.9474 - val_loss: 0.0816 - val_accuracy: 0.9524\n",
            "Epoch 213/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0624 - accuracy: 0.9737 - val_loss: 0.1951 - val_accuracy: 0.9048\n",
            "Epoch 214/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0844 - accuracy: 0.9737 - val_loss: 0.1459 - val_accuracy: 0.9048\n",
            "Epoch 215/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0572 - accuracy: 0.9825 - val_loss: 0.0752 - val_accuracy: 0.9524\n",
            "Epoch 216/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0701 - accuracy: 0.9825 - val_loss: 0.1001 - val_accuracy: 0.9524\n",
            "Epoch 217/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0504 - accuracy: 0.9737 - val_loss: 0.1559 - val_accuracy: 0.9048\n",
            "Epoch 218/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0585 - accuracy: 0.9737 - val_loss: 0.1472 - val_accuracy: 0.9048\n",
            "Epoch 219/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0568 - accuracy: 0.9825 - val_loss: 0.0774 - val_accuracy: 0.9524\n",
            "Epoch 220/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
            "Epoch 221/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0566 - accuracy: 0.9737 - val_loss: 0.1417 - val_accuracy: 0.9048\n",
            "Epoch 222/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0568 - accuracy: 0.9737 - val_loss: 0.1346 - val_accuracy: 0.9048\n",
            "Epoch 223/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0505 - accuracy: 0.9825 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 224/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0707 - accuracy: 0.9737 - val_loss: 0.1570 - val_accuracy: 0.9048\n",
            "Epoch 225/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0611 - accuracy: 0.9737 - val_loss: 0.2136 - val_accuracy: 0.9048\n",
            "Epoch 226/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0786 - accuracy: 0.9737 - val_loss: 0.1216 - val_accuracy: 0.9048\n",
            "Epoch 227/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0514 - accuracy: 0.9825 - val_loss: 0.0647 - val_accuracy: 1.0000\n",
            "Epoch 228/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0605 - accuracy: 0.9825 - val_loss: 0.0840 - val_accuracy: 0.9524\n",
            "Epoch 229/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0527 - accuracy: 0.9825 - val_loss: 0.1358 - val_accuracy: 0.9048\n",
            "Epoch 230/800\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0561 - accuracy: 0.9825 - val_loss: 0.1289 - val_accuracy: 0.9048\n",
            "Epoch 231/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0468 - accuracy: 0.9825 - val_loss: 0.0610 - val_accuracy: 0.9524\n",
            "Epoch 232/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0595 - accuracy: 0.9737 - val_loss: 0.0930 - val_accuracy: 0.9524\n",
            "Epoch 233/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 0.0925 - val_accuracy: 0.9524\n",
            "Epoch 234/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0485 - accuracy: 0.9825 - val_loss: 0.1067 - val_accuracy: 0.9524\n",
            "Epoch 235/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0476 - accuracy: 0.9825 - val_loss: 0.0784 - val_accuracy: 0.9524\n",
            "Epoch 236/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0508 - accuracy: 0.9737 - val_loss: 0.0857 - val_accuracy: 0.9524\n",
            "Epoch 237/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.1433 - val_accuracy: 0.9048\n",
            "Epoch 238/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0567 - accuracy: 0.9825 - val_loss: 0.1100 - val_accuracy: 0.9524\n",
            "Epoch 239/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0499 - accuracy: 0.9825 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
            "Epoch 240/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0686 - accuracy: 0.9737 - val_loss: 0.1357 - val_accuracy: 0.9048\n",
            "Epoch 241/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0569 - accuracy: 0.9737 - val_loss: 0.1420 - val_accuracy: 0.9048\n",
            "Epoch 242/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0527 - accuracy: 0.9825 - val_loss: 0.0938 - val_accuracy: 0.9524\n",
            "Epoch 243/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0563 - accuracy: 0.9737 - val_loss: 0.0654 - val_accuracy: 0.9524\n",
            "Epoch 244/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.1194 - val_accuracy: 0.9048\n",
            "Epoch 245/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0525 - accuracy: 0.9825 - val_loss: 0.1200 - val_accuracy: 0.9048\n",
            "Epoch 246/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0470 - accuracy: 0.9825 - val_loss: 0.0732 - val_accuracy: 0.9524\n",
            "Epoch 247/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.0563 - val_accuracy: 0.9524\n",
            "Epoch 248/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.0829 - val_accuracy: 0.9524\n",
            "Epoch 249/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0452 - accuracy: 0.9825 - val_loss: 0.1083 - val_accuracy: 0.9524\n",
            "Epoch 250/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0490 - accuracy: 0.9825 - val_loss: 0.0707 - val_accuracy: 0.9524\n",
            "Epoch 251/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0449 - accuracy: 0.9825 - val_loss: 0.0866 - val_accuracy: 0.9524\n",
            "Epoch 252/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.1055 - val_accuracy: 0.9524\n",
            "Epoch 253/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0447 - accuracy: 0.9825 - val_loss: 0.0757 - val_accuracy: 0.9524\n",
            "Epoch 254/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0539 - accuracy: 0.9737 - val_loss: 0.1122 - val_accuracy: 0.9524\n",
            "Epoch 255/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0500 - accuracy: 0.9825 - val_loss: 0.2144 - val_accuracy: 0.9048\n",
            "Epoch 256/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0951 - accuracy: 0.9737 - val_loss: 0.1277 - val_accuracy: 0.9048\n",
            "Epoch 257/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0735 - accuracy: 0.9825 - val_loss: 0.0626 - val_accuracy: 1.0000\n",
            "Epoch 258/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0856 - accuracy: 0.9649 - val_loss: 0.1635 - val_accuracy: 0.9048\n",
            "Epoch 259/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0792 - accuracy: 0.9561 - val_loss: 0.1903 - val_accuracy: 0.9048\n",
            "Epoch 260/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0743 - accuracy: 0.9825 - val_loss: 0.0752 - val_accuracy: 1.0000\n",
            "Epoch 261/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0849 - accuracy: 0.9737 - val_loss: 0.0839 - val_accuracy: 0.9524\n",
            "Epoch 262/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0506 - accuracy: 0.9737 - val_loss: 0.2362 - val_accuracy: 0.9048\n",
            "Epoch 263/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0889 - accuracy: 0.9737 - val_loss: 0.1860 - val_accuracy: 0.9048\n",
            "Epoch 264/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.0695 - val_accuracy: 0.9524\n",
            "Epoch 265/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0528 - accuracy: 0.9825 - val_loss: 0.0503 - val_accuracy: 1.0000\n",
            "Epoch 266/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0721 - accuracy: 0.9737 - val_loss: 0.1778 - val_accuracy: 0.9048\n",
            "Epoch 267/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0648 - accuracy: 0.9737 - val_loss: 0.2166 - val_accuracy: 0.9048\n",
            "Epoch 268/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0728 - accuracy: 0.9737 - val_loss: 0.1224 - val_accuracy: 0.9048\n",
            "Epoch 269/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0591 - accuracy: 0.9825 - val_loss: 0.0848 - val_accuracy: 0.9524\n",
            "Epoch 270/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0543 - accuracy: 0.9825 - val_loss: 0.1218 - val_accuracy: 0.9048\n",
            "Epoch 271/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0509 - accuracy: 0.9737 - val_loss: 0.1501 - val_accuracy: 0.9048\n",
            "Epoch 272/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0505 - accuracy: 0.9825 - val_loss: 0.1014 - val_accuracy: 0.9524\n",
            "Epoch 273/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0476 - accuracy: 0.9737 - val_loss: 0.0719 - val_accuracy: 0.9524\n",
            "Epoch 274/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0585 - accuracy: 0.9737 - val_loss: 0.1465 - val_accuracy: 0.9048\n",
            "Epoch 275/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.0903 - val_accuracy: 0.9524\n",
            "Epoch 276/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0463 - accuracy: 0.9825 - val_loss: 0.0753 - val_accuracy: 0.9524\n",
            "Epoch 277/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0503 - accuracy: 0.9737 - val_loss: 0.1213 - val_accuracy: 0.9524\n",
            "Epoch 278/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0460 - accuracy: 0.9825 - val_loss: 0.1272 - val_accuracy: 0.9048\n",
            "Epoch 279/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0470 - accuracy: 0.9825 - val_loss: 0.1035 - val_accuracy: 0.9524\n",
            "Epoch 280/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.9825 - val_loss: 0.0984 - val_accuracy: 0.9524\n",
            "Epoch 281/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
            "Epoch 282/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.1723 - val_accuracy: 0.9048\n",
            "Epoch 283/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0891 - accuracy: 0.9737 - val_loss: 0.2270 - val_accuracy: 0.9048\n",
            "Epoch 284/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0732 - accuracy: 0.9825 - val_loss: 0.0860 - val_accuracy: 0.9524\n",
            "Epoch 285/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0476 - accuracy: 0.9825 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 286/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0659 - accuracy: 0.9737 - val_loss: 0.1489 - val_accuracy: 0.9048\n",
            "Epoch 287/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0577 - accuracy: 0.9737 - val_loss: 0.1968 - val_accuracy: 0.9048\n",
            "Epoch 288/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0650 - accuracy: 0.9737 - val_loss: 0.1515 - val_accuracy: 0.9048\n",
            "Epoch 289/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0472 - accuracy: 0.9825 - val_loss: 0.0853 - val_accuracy: 0.9524\n",
            "Epoch 290/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0535 - accuracy: 0.9825 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
            "Epoch 291/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0580 - accuracy: 0.9825 - val_loss: 0.1624 - val_accuracy: 0.9048\n",
            "Epoch 292/800\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0716 - accuracy: 0.9737 - val_loss: 0.2010 - val_accuracy: 0.9048\n",
            "Epoch 293/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.0720 - val_accuracy: 0.9524\n",
            "Epoch 294/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0538 - accuracy: 0.9825 - val_loss: 0.0826 - val_accuracy: 0.9524\n",
            "Epoch 295/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.1209 - val_accuracy: 0.9524\n",
            "Epoch 296/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0504 - accuracy: 0.9825 - val_loss: 0.1227 - val_accuracy: 0.9524\n",
            "Epoch 297/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0467 - accuracy: 0.9825 - val_loss: 0.0956 - val_accuracy: 0.9524\n",
            "Epoch 298/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0450 - accuracy: 0.9825 - val_loss: 0.0862 - val_accuracy: 0.9524\n",
            "Epoch 299/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 0.0957 - val_accuracy: 0.9524\n",
            "Epoch 300/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.1272 - val_accuracy: 0.9524\n",
            "Epoch 301/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0471 - accuracy: 0.9825 - val_loss: 0.0723 - val_accuracy: 0.9524\n",
            "Epoch 302/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0516 - accuracy: 0.9825 - val_loss: 0.1238 - val_accuracy: 0.9524\n",
            "Epoch 303/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.1410 - val_accuracy: 0.9524\n",
            "Epoch 304/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0480 - accuracy: 0.9825 - val_loss: 0.1067 - val_accuracy: 0.9524\n",
            "Epoch 305/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0487 - accuracy: 0.9737 - val_loss: 0.0772 - val_accuracy: 0.9524\n",
            "Epoch 306/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0451 - accuracy: 0.9825 - val_loss: 0.1101 - val_accuracy: 0.9524\n",
            "Epoch 307/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0416 - accuracy: 0.9825 - val_loss: 0.1300 - val_accuracy: 0.9524\n",
            "Epoch 308/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.1049 - val_accuracy: 0.9524\n",
            "Epoch 309/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.9825 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 310/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0598 - accuracy: 0.9825 - val_loss: 0.1218 - val_accuracy: 0.9524\n",
            "Epoch 311/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0509 - accuracy: 0.9825 - val_loss: 0.1363 - val_accuracy: 0.9524\n",
            "Epoch 312/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.0795 - val_accuracy: 0.9524\n",
            "Epoch 313/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0712 - accuracy: 0.9825 - val_loss: 0.0876 - val_accuracy: 0.9524\n",
            "Epoch 314/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0567 - accuracy: 0.9737 - val_loss: 0.1803 - val_accuracy: 0.9048\n",
            "Epoch 315/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0624 - accuracy: 0.9737 - val_loss: 0.1094 - val_accuracy: 0.9524\n",
            "Epoch 316/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0515 - accuracy: 0.9737 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
            "Epoch 317/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0545 - accuracy: 0.9737 - val_loss: 0.1509 - val_accuracy: 0.9048\n",
            "Epoch 318/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.1565 - val_accuracy: 0.9048\n",
            "Epoch 319/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0599 - accuracy: 0.9825 - val_loss: 0.0878 - val_accuracy: 0.9524\n",
            "Epoch 320/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0522 - accuracy: 0.9737 - val_loss: 0.0975 - val_accuracy: 0.9524\n",
            "Epoch 321/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0458 - accuracy: 0.9825 - val_loss: 0.1339 - val_accuracy: 0.9048\n",
            "Epoch 322/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0450 - accuracy: 0.9825 - val_loss: 0.1173 - val_accuracy: 0.9048\n",
            "Epoch 323/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.0862 - val_accuracy: 0.9524\n",
            "Epoch 324/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0431 - accuracy: 0.9825 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
            "Epoch 325/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0469 - accuracy: 0.9825 - val_loss: 0.1009 - val_accuracy: 0.9524\n",
            "Epoch 326/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0596 - accuracy: 0.9825 - val_loss: 0.1779 - val_accuracy: 0.9048\n",
            "Epoch 327/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
            "Epoch 328/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0665 - accuracy: 0.9737 - val_loss: 0.1297 - val_accuracy: 0.9048\n",
            "Epoch 329/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.2029 - val_accuracy: 0.9048\n",
            "Epoch 330/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0625 - accuracy: 0.9737 - val_loss: 0.1205 - val_accuracy: 0.9524\n",
            "Epoch 331/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0544 - accuracy: 0.9825 - val_loss: 0.0482 - val_accuracy: 1.0000\n",
            "Epoch 332/800\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0656 - accuracy: 0.9737 - val_loss: 0.1930 - val_accuracy: 0.9048\n",
            "Epoch 333/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0810 - accuracy: 0.9737 - val_loss: 0.1659 - val_accuracy: 0.9048\n",
            "Epoch 334/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0587 - accuracy: 0.9649 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
            "Epoch 335/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0676 - accuracy: 0.9737 - val_loss: 0.1429 - val_accuracy: 0.9048\n",
            "Epoch 336/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0460 - accuracy: 0.9825 - val_loss: 0.1815 - val_accuracy: 0.9048\n",
            "Epoch 337/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0646 - accuracy: 0.9737 - val_loss: 0.1250 - val_accuracy: 0.9524\n",
            "Epoch 338/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.0486 - val_accuracy: 1.0000\n",
            "Epoch 339/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0552 - accuracy: 0.9825 - val_loss: 0.1117 - val_accuracy: 0.9524\n",
            "Epoch 340/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0380 - accuracy: 0.9825 - val_loss: 0.1760 - val_accuracy: 0.9048\n",
            "Epoch 341/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0537 - accuracy: 0.9825 - val_loss: 0.1496 - val_accuracy: 0.9048\n",
            "Epoch 342/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0513 - accuracy: 0.9825 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
            "Epoch 343/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0573 - accuracy: 0.9825 - val_loss: 0.1298 - val_accuracy: 0.9524\n",
            "Epoch 344/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0402 - accuracy: 0.9825 - val_loss: 0.2047 - val_accuracy: 0.9048\n",
            "Epoch 345/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0611 - accuracy: 0.9737 - val_loss: 0.1310 - val_accuracy: 0.9524\n",
            "Epoch 346/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0381 - accuracy: 0.9825 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
            "Epoch 347/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0536 - accuracy: 0.9737 - val_loss: 0.1437 - val_accuracy: 0.9524\n",
            "Epoch 348/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0394 - accuracy: 0.9825 - val_loss: 0.1610 - val_accuracy: 0.9048\n",
            "Epoch 349/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0465 - accuracy: 0.9825 - val_loss: 0.1403 - val_accuracy: 0.9524\n",
            "Epoch 350/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0387 - accuracy: 0.9825 - val_loss: 0.0787 - val_accuracy: 0.9524\n",
            "Epoch 351/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0401 - accuracy: 0.9912 - val_loss: 0.0577 - val_accuracy: 1.0000\n",
            "Epoch 352/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0408 - accuracy: 0.9825 - val_loss: 0.1132 - val_accuracy: 0.9524\n",
            "Epoch 353/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0380 - accuracy: 0.9825 - val_loss: 0.1550 - val_accuracy: 0.9524\n",
            "Epoch 354/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0468 - accuracy: 0.9825 - val_loss: 0.1442 - val_accuracy: 0.9524\n",
            "Epoch 355/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 0.9825 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
            "Epoch 356/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0455 - accuracy: 0.9825 - val_loss: 0.1444 - val_accuracy: 0.9524\n",
            "Epoch 357/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0438 - accuracy: 0.9825 - val_loss: 0.2009 - val_accuracy: 0.9048\n",
            "Epoch 358/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 0.0795 - val_accuracy: 0.9524\n",
            "Epoch 359/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0403 - accuracy: 0.9912 - val_loss: 0.0906 - val_accuracy: 0.9524\n",
            "Epoch 360/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0378 - accuracy: 0.9825 - val_loss: 0.1406 - val_accuracy: 0.9524\n",
            "Epoch 361/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - accuracy: 0.9825 - val_loss: 0.1578 - val_accuracy: 0.9524\n",
            "Epoch 362/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0380 - accuracy: 0.9825 - val_loss: 0.1565 - val_accuracy: 0.9524\n",
            "Epoch 363/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9825 - val_loss: 0.1425 - val_accuracy: 0.9524\n",
            "Epoch 364/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0372 - accuracy: 0.9825 - val_loss: 0.1462 - val_accuracy: 0.9524\n",
            "Epoch 365/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0350 - accuracy: 0.9825 - val_loss: 0.1091 - val_accuracy: 0.9524\n",
            "Epoch 366/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0438 - accuracy: 0.9825 - val_loss: 0.0790 - val_accuracy: 0.9524\n",
            "Epoch 367/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0351 - accuracy: 0.9825 - val_loss: 0.1533 - val_accuracy: 0.9524\n",
            "Epoch 368/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.9825 - val_loss: 0.1663 - val_accuracy: 0.9524\n",
            "Epoch 369/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0380 - accuracy: 0.9912 - val_loss: 0.1114 - val_accuracy: 0.9524\n",
            "Epoch 370/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0334 - accuracy: 0.9912 - val_loss: 0.0989 - val_accuracy: 0.9524\n",
            "Epoch 371/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.0909 - val_accuracy: 0.9524\n",
            "Epoch 372/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.1087 - val_accuracy: 0.9524\n",
            "Epoch 373/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0329 - accuracy: 0.9912 - val_loss: 0.0856 - val_accuracy: 0.9524\n",
            "Epoch 374/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
            "Epoch 375/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0333 - accuracy: 0.9825 - val_loss: 0.1797 - val_accuracy: 0.9524\n",
            "Epoch 376/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
            "Epoch 377/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0480 - accuracy: 0.9825 - val_loss: 0.1798 - val_accuracy: 0.9524\n",
            "Epoch 378/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0485 - accuracy: 0.9825 - val_loss: 0.2438 - val_accuracy: 0.9048\n",
            "Epoch 379/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0386 - accuracy: 0.9825 - val_loss: 0.1348 - val_accuracy: 0.9524\n",
            "Epoch 380/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.0655 - val_accuracy: 1.0000\n",
            "Epoch 381/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.1269 - val_accuracy: 0.9524\n",
            "Epoch 382/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0358 - accuracy: 0.9825 - val_loss: 0.1816 - val_accuracy: 0.9524\n",
            "Epoch 383/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0337 - accuracy: 0.9825 - val_loss: 0.1627 - val_accuracy: 0.9524\n",
            "Epoch 384/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0369 - accuracy: 0.9825 - val_loss: 0.1538 - val_accuracy: 0.9524\n",
            "Epoch 385/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0428 - accuracy: 0.9825 - val_loss: 0.0883 - val_accuracy: 0.9524\n",
            "Epoch 386/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
            "Epoch 387/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0404 - accuracy: 0.9825 - val_loss: 0.2378 - val_accuracy: 0.9524\n",
            "Epoch 388/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0761 - accuracy: 0.9737 - val_loss: 0.0917 - val_accuracy: 0.9524\n",
            "Epoch 389/800\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0454 - accuracy: 0.9825 - val_loss: 0.0529 - val_accuracy: 1.0000\n",
            "Epoch 390/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0362 - accuracy: 0.9912 - val_loss: 0.2432 - val_accuracy: 0.9524\n",
            "Epoch 391/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0400 - accuracy: 0.9825 - val_loss: 0.2290 - val_accuracy: 0.9524\n",
            "Epoch 392/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0362 - accuracy: 0.9825 - val_loss: 0.1704 - val_accuracy: 0.9524\n",
            "Epoch 393/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0327 - accuracy: 0.9912 - val_loss: 0.1443 - val_accuracy: 0.9524\n",
            "Epoch 394/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0341 - accuracy: 0.9912 - val_loss: 0.0928 - val_accuracy: 0.9524\n",
            "Epoch 395/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.0793 - val_accuracy: 0.9524\n",
            "Epoch 396/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.0922 - val_accuracy: 0.9524\n",
            "Epoch 397/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0385 - accuracy: 0.9825 - val_loss: 0.1194 - val_accuracy: 0.9524\n",
            "Epoch 398/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0374 - accuracy: 0.9825 - val_loss: 0.1581 - val_accuracy: 0.9524\n",
            "Epoch 399/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0412 - accuracy: 0.9825 - val_loss: 0.1919 - val_accuracy: 0.9524\n",
            "Epoch 400/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0435 - accuracy: 0.9912 - val_loss: 0.1051 - val_accuracy: 0.9524\n",
            "Epoch 401/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0381 - accuracy: 0.9825 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
            "Epoch 402/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0393 - accuracy: 0.9825 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
            "Epoch 403/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0425 - accuracy: 0.9825 - val_loss: 0.0801 - val_accuracy: 0.9524\n",
            "Epoch 404/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0367 - accuracy: 0.9825 - val_loss: 0.1086 - val_accuracy: 0.9524\n",
            "Epoch 405/800\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.0388 - val_accuracy: 1.0000\n",
            "Epoch 406/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0365 - accuracy: 0.9825 - val_loss: 0.0665 - val_accuracy: 0.9524\n",
            "Epoch 407/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0314 - accuracy: 0.9825 - val_loss: 0.1825 - val_accuracy: 0.9524\n",
            "Epoch 408/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0335 - accuracy: 0.9825 - val_loss: 0.0987 - val_accuracy: 0.9524\n",
            "Epoch 409/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0471 - accuracy: 0.9825 - val_loss: 0.1247 - val_accuracy: 0.9524\n",
            "Epoch 410/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0362 - accuracy: 0.9825 - val_loss: 0.1556 - val_accuracy: 0.9524\n",
            "Epoch 411/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0556 - accuracy: 0.9825 - val_loss: 0.1742 - val_accuracy: 0.9524\n",
            "Epoch 412/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0351 - accuracy: 0.9825 - val_loss: 0.0504 - val_accuracy: 1.0000\n",
            "Epoch 413/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0339 - accuracy: 0.9825 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
            "Epoch 414/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0527 - accuracy: 0.9825 - val_loss: 0.1563 - val_accuracy: 0.9524\n",
            "Epoch 415/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1855 - val_accuracy: 0.9524\n",
            "Epoch 416/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0518 - accuracy: 0.9825 - val_loss: 0.1365 - val_accuracy: 0.9524\n",
            "Epoch 417/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0632 - accuracy: 0.9825 - val_loss: 0.1986 - val_accuracy: 0.9524\n",
            "Epoch 418/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0340 - accuracy: 0.9912 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
            "Epoch 419/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0447 - accuracy: 0.9825 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
            "Epoch 420/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0349 - accuracy: 0.9825 - val_loss: 0.2350 - val_accuracy: 0.9524\n",
            "Epoch 421/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0394 - accuracy: 0.9825 - val_loss: 0.1879 - val_accuracy: 0.9524\n",
            "Epoch 422/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0357 - accuracy: 0.9912 - val_loss: 0.1667 - val_accuracy: 0.9524\n",
            "Epoch 423/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0378 - accuracy: 0.9825 - val_loss: 0.1721 - val_accuracy: 0.9524\n",
            "Epoch 424/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.1856 - val_accuracy: 0.9524\n",
            "Epoch 425/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.1219 - val_accuracy: 0.9524\n",
            "Epoch 426/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0339 - accuracy: 0.9825 - val_loss: 0.1120 - val_accuracy: 0.9524\n",
            "Epoch 427/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 0.9912 - val_loss: 0.0965 - val_accuracy: 0.9524\n",
            "Epoch 428/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.0801 - val_accuracy: 0.9524\n",
            "Epoch 429/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0360 - accuracy: 0.9825 - val_loss: 0.1770 - val_accuracy: 0.9524\n",
            "Epoch 430/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.1065 - val_accuracy: 0.9524\n",
            "Epoch 431/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.0753 - val_accuracy: 0.9524\n",
            "Epoch 432/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.1131 - val_accuracy: 0.9524\n",
            "Epoch 433/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0350 - accuracy: 0.9825 - val_loss: 0.1529 - val_accuracy: 0.9524\n",
            "Epoch 434/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
            "Epoch 435/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0413 - accuracy: 0.9825 - val_loss: 0.3914 - val_accuracy: 0.9048\n",
            "Epoch 436/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0757 - accuracy: 0.9737 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
            "Epoch 437/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0941 - accuracy: 0.9649 - val_loss: 0.3308 - val_accuracy: 0.9048\n",
            "Epoch 438/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.1317 - accuracy: 0.9561 - val_loss: 0.0796 - val_accuracy: 1.0000\n",
            "Epoch 439/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0928 - accuracy: 0.9561 - val_loss: 0.0750 - val_accuracy: 0.9524\n",
            "Epoch 440/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0557 - accuracy: 0.9737 - val_loss: 0.1623 - val_accuracy: 0.9048\n",
            "Epoch 441/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0629 - accuracy: 0.9825 - val_loss: 0.0701 - val_accuracy: 0.9524\n",
            "Epoch 442/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0789 - accuracy: 0.9649 - val_loss: 0.1074 - val_accuracy: 0.9524\n",
            "Epoch 443/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0592 - accuracy: 0.9737 - val_loss: 0.2293 - val_accuracy: 0.9048\n",
            "Epoch 444/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0963 - accuracy: 0.9649 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
            "Epoch 445/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0547 - accuracy: 0.9825 - val_loss: 0.1329 - val_accuracy: 0.9048\n",
            "Epoch 446/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0513 - accuracy: 0.9825 - val_loss: 0.1002 - val_accuracy: 0.9524\n",
            "Epoch 447/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0479 - accuracy: 0.9912 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 448/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.1212 - val_accuracy: 0.9048\n",
            "Epoch 449/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0468 - accuracy: 0.9825 - val_loss: 0.1186 - val_accuracy: 0.9048\n",
            "Epoch 450/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0506 - accuracy: 0.9825 - val_loss: 0.0734 - val_accuracy: 0.9524\n",
            "Epoch 451/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0500 - accuracy: 0.9825 - val_loss: 0.0783 - val_accuracy: 0.9524\n",
            "Epoch 452/800\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.1014 - val_accuracy: 0.9524\n",
            "Epoch 453/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 0.0694 - val_accuracy: 0.9524\n",
            "Epoch 454/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0470 - accuracy: 0.9912 - val_loss: 0.1006 - val_accuracy: 0.9524\n",
            "Epoch 455/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0433 - accuracy: 0.9825 - val_loss: 0.0828 - val_accuracy: 0.9524\n",
            "Epoch 456/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0412 - accuracy: 0.9825 - val_loss: 0.0618 - val_accuracy: 0.9524\n",
            "Epoch 457/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 0.1640 - val_accuracy: 0.9048\n",
            "Epoch 458/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.0773 - val_accuracy: 0.9524\n",
            "Epoch 459/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0405 - accuracy: 0.9825 - val_loss: 0.0751 - val_accuracy: 0.9524\n",
            "Epoch 460/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0479 - accuracy: 0.9737 - val_loss: 0.1099 - val_accuracy: 0.9524\n",
            "Epoch 461/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0454 - accuracy: 0.9825 - val_loss: 0.0684 - val_accuracy: 0.9524\n",
            "Epoch 462/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 0.9825 - val_loss: 0.1215 - val_accuracy: 0.9524\n",
            "Epoch 463/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0431 - accuracy: 0.9825 - val_loss: 0.1540 - val_accuracy: 0.9048\n",
            "Epoch 464/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0467 - accuracy: 0.9825 - val_loss: 0.0880 - val_accuracy: 0.9524\n",
            "Epoch 465/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0746 - accuracy: 0.9825 - val_loss: 0.1274 - val_accuracy: 0.9524\n",
            "Epoch 466/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0669 - accuracy: 0.9737 - val_loss: 0.2004 - val_accuracy: 0.9048\n",
            "Epoch 467/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0476 - accuracy: 0.9825 - val_loss: 0.0833 - val_accuracy: 0.9524\n",
            "Epoch 468/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0514 - accuracy: 0.9825 - val_loss: 0.0794 - val_accuracy: 0.9524\n",
            "Epoch 469/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.1420 - val_accuracy: 0.9048\n",
            "Epoch 470/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0447 - accuracy: 0.9825 - val_loss: 0.0790 - val_accuracy: 0.9524\n",
            "Epoch 471/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.0835 - val_accuracy: 0.9524\n",
            "Epoch 472/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0413 - accuracy: 0.9825 - val_loss: 0.0923 - val_accuracy: 0.9524\n",
            "Epoch 473/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0412 - accuracy: 0.9737 - val_loss: 0.1027 - val_accuracy: 0.9524\n",
            "Epoch 474/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0401 - accuracy: 0.9825 - val_loss: 0.1120 - val_accuracy: 0.9524\n",
            "Epoch 475/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 0.0713 - val_accuracy: 0.9524\n",
            "Epoch 476/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0432 - accuracy: 0.9825 - val_loss: 0.0658 - val_accuracy: 0.9524\n",
            "Epoch 477/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0374 - accuracy: 0.9825 - val_loss: 0.1118 - val_accuracy: 0.9524\n",
            "Epoch 478/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0605 - accuracy: 0.9825 - val_loss: 0.1398 - val_accuracy: 0.9524\n",
            "Epoch 479/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0692 - accuracy: 0.9737 - val_loss: 0.0445 - val_accuracy: 1.0000\n",
            "Epoch 480/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0859 - accuracy: 0.9737 - val_loss: 0.2818 - val_accuracy: 0.9048\n",
            "Epoch 481/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0838 - accuracy: 0.9737 - val_loss: 0.1191 - val_accuracy: 0.9524\n",
            "Epoch 482/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0493 - accuracy: 0.9825 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
            "Epoch 483/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.1356 - val_accuracy: 0.9048\n",
            "Epoch 484/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0456 - accuracy: 0.9825 - val_loss: 0.1644 - val_accuracy: 0.9048\n",
            "Epoch 485/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0489 - accuracy: 0.9825 - val_loss: 0.1202 - val_accuracy: 0.9524\n",
            "Epoch 486/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0443 - accuracy: 0.9825 - val_loss: 0.0729 - val_accuracy: 0.9524\n",
            "Epoch 487/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0479 - accuracy: 0.9825 - val_loss: 0.0954 - val_accuracy: 0.9524\n",
            "Epoch 488/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0397 - accuracy: 0.9825 - val_loss: 0.1135 - val_accuracy: 0.9524\n",
            "Epoch 489/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.1170 - val_accuracy: 0.9524\n",
            "Epoch 490/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0387 - accuracy: 0.9737 - val_loss: 0.0666 - val_accuracy: 0.9524\n",
            "Epoch 491/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9825 - val_loss: 0.0869 - val_accuracy: 0.9524\n",
            "Epoch 492/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0439 - accuracy: 0.9912 - val_loss: 0.1809 - val_accuracy: 0.9048\n",
            "Epoch 493/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0488 - accuracy: 0.9825 - val_loss: 0.0848 - val_accuracy: 0.9524\n",
            "Epoch 494/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0385 - accuracy: 0.9825 - val_loss: 0.0662 - val_accuracy: 0.9524\n",
            "Epoch 495/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0404 - accuracy: 0.9825 - val_loss: 0.0917 - val_accuracy: 0.9524\n",
            "Epoch 496/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 0.1354 - val_accuracy: 0.9524\n",
            "Epoch 497/800\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.0594 - accuracy: 0.9737 - val_loss: 0.0803 - val_accuracy: 0.9524\n",
            "Epoch 498/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0526 - accuracy: 0.9737 - val_loss: 0.1469 - val_accuracy: 0.9524\n",
            "Epoch 499/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0354 - accuracy: 0.9825 - val_loss: 0.0672 - val_accuracy: 0.9524\n",
            "Epoch 500/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0475 - accuracy: 0.9825 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
            "Epoch 501/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0417 - accuracy: 0.9912 - val_loss: 0.1287 - val_accuracy: 0.9524\n",
            "Epoch 502/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0588 - accuracy: 0.9825 - val_loss: 0.2093 - val_accuracy: 0.9048\n",
            "Epoch 503/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0522 - accuracy: 0.9825 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 504/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1072 - accuracy: 0.9561 - val_loss: 0.1731 - val_accuracy: 0.9048\n",
            "Epoch 505/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0785 - accuracy: 0.9649 - val_loss: 0.2793 - val_accuracy: 0.9048\n",
            "Epoch 506/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0811 - accuracy: 0.9737 - val_loss: 0.0804 - val_accuracy: 0.9524\n",
            "Epoch 507/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0653 - accuracy: 0.9825 - val_loss: 0.0794 - val_accuracy: 0.9524\n",
            "Epoch 508/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0512 - accuracy: 0.9825 - val_loss: 0.1684 - val_accuracy: 0.9048\n",
            "Epoch 509/800\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.1825 - val_accuracy: 0.9048\n",
            "Epoch 510/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0522 - accuracy: 0.9825 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
            "Epoch 511/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 512/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0529 - accuracy: 0.9737 - val_loss: 0.1527 - val_accuracy: 0.9048\n",
            "Epoch 513/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0490 - accuracy: 0.9825 - val_loss: 0.1381 - val_accuracy: 0.9048\n",
            "Epoch 514/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 0.9825 - val_loss: 0.1074 - val_accuracy: 0.9048\n",
            "Epoch 515/800\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.0426 - accuracy: 0.9825 - val_loss: 0.0774 - val_accuracy: 0.9524\n",
            "Epoch 516/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0427 - accuracy: 0.9737 - val_loss: 0.1160 - val_accuracy: 0.9524\n",
            "Epoch 517/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0387 - accuracy: 0.9825 - val_loss: 0.1428 - val_accuracy: 0.9048\n",
            "Epoch 518/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0411 - accuracy: 0.9825 - val_loss: 0.1272 - val_accuracy: 0.9524\n",
            "Epoch 519/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0386 - accuracy: 0.9825 - val_loss: 0.1139 - val_accuracy: 0.9524\n",
            "Epoch 520/800\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0375 - accuracy: 0.9825 - val_loss: 0.1057 - val_accuracy: 0.9524\n",
            "Epoch 521/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0371 - accuracy: 0.9825 - val_loss: 0.1027 - val_accuracy: 0.9524\n",
            "Epoch 522/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0386 - accuracy: 0.9825 - val_loss: 0.1246 - val_accuracy: 0.9524\n",
            "Epoch 523/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0361 - accuracy: 0.9825 - val_loss: 0.0828 - val_accuracy: 0.9524\n",
            "Epoch 524/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0372 - accuracy: 0.9825 - val_loss: 0.1171 - val_accuracy: 0.9524\n",
            "Epoch 525/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0549 - accuracy: 0.9825 - val_loss: 0.1413 - val_accuracy: 0.9524\n",
            "Epoch 526/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0350 - accuracy: 0.9737 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
            "Epoch 527/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0469 - accuracy: 0.9825 - val_loss: 0.1228 - val_accuracy: 0.9524\n",
            "Epoch 528/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0314 - accuracy: 0.9825 - val_loss: 0.2405 - val_accuracy: 0.9048\n",
            "Epoch 529/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0571 - accuracy: 0.9825 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
            "Epoch 530/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.1419 - val_accuracy: 0.9524\n",
            "Epoch 531/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0393 - accuracy: 0.9825 - val_loss: 0.2995 - val_accuracy: 0.9048\n",
            "Epoch 532/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0856 - accuracy: 0.9737 - val_loss: 0.1104 - val_accuracy: 0.9524\n",
            "Epoch 533/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0579 - accuracy: 0.9825 - val_loss: 0.0896 - val_accuracy: 0.9524\n",
            "Epoch 534/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.1255 - val_accuracy: 0.9524\n",
            "Epoch 535/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0476 - accuracy: 0.9737 - val_loss: 0.2189 - val_accuracy: 0.9048\n",
            "Epoch 536/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0639 - accuracy: 0.9737 - val_loss: 0.1178 - val_accuracy: 0.9524\n",
            "Epoch 537/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0399 - accuracy: 0.9825 - val_loss: 0.0863 - val_accuracy: 0.9524\n",
            "Epoch 538/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0472 - accuracy: 0.9825 - val_loss: 0.0931 - val_accuracy: 0.9524\n",
            "Epoch 539/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0399 - accuracy: 0.9737 - val_loss: 0.1339 - val_accuracy: 0.9524\n",
            "Epoch 540/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0503 - accuracy: 0.9825 - val_loss: 0.1437 - val_accuracy: 0.9524\n",
            "Epoch 541/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0384 - accuracy: 0.9737 - val_loss: 0.0639 - val_accuracy: 0.9524\n",
            "Epoch 542/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.1602 - val_accuracy: 0.9048\n",
            "Epoch 543/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0510 - accuracy: 0.9737 - val_loss: 0.2197 - val_accuracy: 0.9048\n",
            "Epoch 544/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0525 - accuracy: 0.9737 - val_loss: 0.1292 - val_accuracy: 0.9524\n",
            "Epoch 545/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.0748 - val_accuracy: 0.9524\n",
            "Epoch 546/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0516 - accuracy: 0.9825 - val_loss: 0.1337 - val_accuracy: 0.9524\n",
            "Epoch 547/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0478 - accuracy: 0.9825 - val_loss: 0.1683 - val_accuracy: 0.9048\n",
            "Epoch 548/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9825 - val_loss: 0.0944 - val_accuracy: 0.9524\n",
            "Epoch 549/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0699 - accuracy: 0.9737 - val_loss: 0.1296 - val_accuracy: 0.9048\n",
            "Epoch 550/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0681 - accuracy: 0.9825 - val_loss: 0.2813 - val_accuracy: 0.9048\n",
            "Epoch 551/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0797 - accuracy: 0.9825 - val_loss: 0.0944 - val_accuracy: 0.9524\n",
            "Epoch 552/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0706 - accuracy: 0.9825 - val_loss: 0.0898 - val_accuracy: 0.9524\n",
            "Epoch 553/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0512 - accuracy: 0.9912 - val_loss: 0.1650 - val_accuracy: 0.9048\n",
            "Epoch 554/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0506 - accuracy: 0.9825 - val_loss: 0.1729 - val_accuracy: 0.9048\n",
            "Epoch 555/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0422 - accuracy: 0.9825 - val_loss: 0.0866 - val_accuracy: 0.9524\n",
            "Epoch 556/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0513 - accuracy: 0.9825 - val_loss: 0.0693 - val_accuracy: 0.9524\n",
            "Epoch 557/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0398 - accuracy: 0.9825 - val_loss: 0.1334 - val_accuracy: 0.9048\n",
            "Epoch 558/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0573 - accuracy: 0.9825 - val_loss: 0.1972 - val_accuracy: 0.9048\n",
            "Epoch 559/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.1034 - val_accuracy: 0.9524\n",
            "Epoch 560/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0419 - accuracy: 0.9825 - val_loss: 0.0907 - val_accuracy: 0.9524\n",
            "Epoch 561/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.1081 - val_accuracy: 0.9524\n",
            "Epoch 562/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0430 - accuracy: 0.9825 - val_loss: 0.1718 - val_accuracy: 0.9048\n",
            "Epoch 563/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0439 - accuracy: 0.9825 - val_loss: 0.1429 - val_accuracy: 0.9524\n",
            "Epoch 564/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0379 - accuracy: 0.9825 - val_loss: 0.1242 - val_accuracy: 0.9524\n",
            "Epoch 565/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0384 - accuracy: 0.9825 - val_loss: 0.1055 - val_accuracy: 0.9524\n",
            "Epoch 566/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0396 - accuracy: 0.9825 - val_loss: 0.1341 - val_accuracy: 0.9524\n",
            "Epoch 567/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0376 - accuracy: 0.9912 - val_loss: 0.1109 - val_accuracy: 0.9524\n",
            "Epoch 568/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0366 - accuracy: 0.9825 - val_loss: 0.1277 - val_accuracy: 0.9524\n",
            "Epoch 569/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0364 - accuracy: 0.9825 - val_loss: 0.1331 - val_accuracy: 0.9524\n",
            "Epoch 570/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0350 - accuracy: 0.9825 - val_loss: 0.1151 - val_accuracy: 0.9524\n",
            "Epoch 571/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0343 - accuracy: 0.9912 - val_loss: 0.1090 - val_accuracy: 0.9524\n",
            "Epoch 572/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0338 - accuracy: 0.9825 - val_loss: 0.1581 - val_accuracy: 0.9524\n",
            "Epoch 573/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.1409 - val_accuracy: 0.9524\n",
            "Epoch 574/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0338 - accuracy: 0.9912 - val_loss: 0.0978 - val_accuracy: 0.9524\n",
            "Epoch 575/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0368 - accuracy: 0.9825 - val_loss: 0.1701 - val_accuracy: 0.9524\n",
            "Epoch 576/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0309 - accuracy: 0.9825 - val_loss: 0.2537 - val_accuracy: 0.9524\n",
            "Epoch 577/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0542 - accuracy: 0.9825 - val_loss: 0.1802 - val_accuracy: 0.9524\n",
            "Epoch 578/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0666 - accuracy: 0.9737 - val_loss: 0.0848 - val_accuracy: 1.0000\n",
            "Epoch 579/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.1382 - val_accuracy: 0.9048\n",
            "Epoch 580/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0558 - accuracy: 0.9737 - val_loss: 0.2064 - val_accuracy: 0.9048\n",
            "Epoch 581/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0565 - accuracy: 0.9737 - val_loss: 0.1019 - val_accuracy: 0.9524\n",
            "Epoch 582/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0403 - accuracy: 0.9912 - val_loss: 0.0779 - val_accuracy: 0.9524\n",
            "Epoch 583/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0431 - accuracy: 0.9825 - val_loss: 0.0930 - val_accuracy: 0.9524\n",
            "Epoch 584/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0369 - accuracy: 0.9825 - val_loss: 0.2002 - val_accuracy: 0.9524\n",
            "Epoch 585/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0564 - accuracy: 0.9825 - val_loss: 0.1251 - val_accuracy: 0.9524\n",
            "Epoch 586/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0501 - accuracy: 0.9825 - val_loss: 0.0581 - val_accuracy: 0.9524\n",
            "Epoch 587/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0416 - accuracy: 0.9825 - val_loss: 0.1148 - val_accuracy: 0.9524\n",
            "Epoch 588/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0390 - accuracy: 0.9825 - val_loss: 0.1602 - val_accuracy: 0.9524\n",
            "Epoch 589/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0401 - accuracy: 0.9825 - val_loss: 0.1030 - val_accuracy: 0.9524\n",
            "Epoch 590/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0414 - accuracy: 0.9825 - val_loss: 0.0885 - val_accuracy: 0.9524\n",
            "Epoch 591/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0357 - accuracy: 0.9825 - val_loss: 0.1792 - val_accuracy: 0.9524\n",
            "Epoch 592/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0455 - accuracy: 0.9825 - val_loss: 0.2045 - val_accuracy: 0.9524\n",
            "Epoch 593/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0316 - accuracy: 0.9825 - val_loss: 0.0863 - val_accuracy: 0.9524\n",
            "Epoch 594/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.0830 - val_accuracy: 0.9524\n",
            "Epoch 595/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0427 - accuracy: 0.9912 - val_loss: 0.2335 - val_accuracy: 0.9524\n",
            "Epoch 596/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0382 - accuracy: 0.9825 - val_loss: 0.1246 - val_accuracy: 0.9524\n",
            "Epoch 597/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0352 - accuracy: 0.9825 - val_loss: 0.1274 - val_accuracy: 0.9524\n",
            "Epoch 598/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.2020 - val_accuracy: 0.9524\n",
            "Epoch 599/800\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.0416 - accuracy: 0.9825 - val_loss: 0.1921 - val_accuracy: 0.9524\n",
            "Epoch 600/800\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0426 - accuracy: 0.9825 - val_loss: 0.0681 - val_accuracy: 0.9524\n",
            "Epoch 601/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0430 - accuracy: 0.9825 - val_loss: 0.1602 - val_accuracy: 0.9524\n",
            "Epoch 602/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 0.3084 - val_accuracy: 0.9048\n",
            "Epoch 603/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0431 - accuracy: 0.9825 - val_loss: 0.1694 - val_accuracy: 0.9524\n",
            "Epoch 604/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0373 - accuracy: 0.9825 - val_loss: 0.1111 - val_accuracy: 0.9524\n",
            "Epoch 605/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0375 - accuracy: 0.9912 - val_loss: 0.1309 - val_accuracy: 0.9524\n",
            "Epoch 606/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.1932 - val_accuracy: 0.9524\n",
            "Epoch 607/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0367 - accuracy: 0.9825 - val_loss: 0.1842 - val_accuracy: 0.9524\n",
            "Epoch 608/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0343 - accuracy: 0.9825 - val_loss: 0.1231 - val_accuracy: 0.9524\n",
            "Epoch 609/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0343 - accuracy: 0.9825 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
            "Epoch 610/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0330 - accuracy: 0.9825 - val_loss: 0.0963 - val_accuracy: 0.9524\n",
            "Epoch 611/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 0.2200 - val_accuracy: 0.9524\n",
            "Epoch 612/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0340 - accuracy: 0.9825 - val_loss: 0.1810 - val_accuracy: 0.9524\n",
            "Epoch 613/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
            "Epoch 614/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0354 - accuracy: 0.9825 - val_loss: 0.0499 - val_accuracy: 0.9524\n",
            "Epoch 615/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.2081 - val_accuracy: 0.9524\n",
            "Epoch 616/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0603 - accuracy: 0.9825 - val_loss: 0.1089 - val_accuracy: 0.9524\n",
            "Epoch 617/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.1288 - val_accuracy: 0.9524\n",
            "Epoch 618/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0548 - accuracy: 0.9649 - val_loss: 0.1676 - val_accuracy: 0.9524\n",
            "Epoch 619/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0409 - accuracy: 0.9912 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
            "Epoch 620/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0542 - accuracy: 0.9825 - val_loss: 0.0354 - val_accuracy: 1.0000\n",
            "Epoch 621/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0565 - accuracy: 0.9825 - val_loss: 0.3623 - val_accuracy: 0.9048\n",
            "Epoch 622/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0626 - accuracy: 0.9825 - val_loss: 0.2911 - val_accuracy: 0.9048\n",
            "Epoch 623/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 0.9825 - val_loss: 0.0362 - val_accuracy: 1.0000\n",
            "Epoch 624/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0464 - accuracy: 0.9825 - val_loss: 0.0363 - val_accuracy: 1.0000\n",
            "Epoch 625/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0502 - accuracy: 0.9825 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
            "Epoch 626/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0356 - accuracy: 0.9825 - val_loss: 0.0925 - val_accuracy: 0.9524\n",
            "Epoch 627/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.1130 - val_accuracy: 0.9524\n",
            "Epoch 628/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0433 - accuracy: 0.9825 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
            "Epoch 629/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0367 - accuracy: 0.9825 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 630/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0363 - accuracy: 0.9825 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 631/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0362 - accuracy: 0.9912 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
            "Epoch 632/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0325 - accuracy: 0.9912 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
            "Epoch 633/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0325 - accuracy: 0.9825 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 634/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 635/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0383 - accuracy: 0.9912 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 636/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0337 - accuracy: 0.9912 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
            "Epoch 637/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.0844 - val_accuracy: 0.9524\n",
            "Epoch 638/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0310 - accuracy: 0.9825 - val_loss: 0.1782 - val_accuracy: 0.9524\n",
            "Epoch 639/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0331 - accuracy: 0.9825 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
            "Epoch 640/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
            "Epoch 641/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 0.9912 - val_loss: 0.1328 - val_accuracy: 0.9524\n",
            "Epoch 642/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0993 - val_accuracy: 0.9524\n",
            "Epoch 643/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
            "Epoch 644/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0998 - val_accuracy: 0.9524\n",
            "Epoch 645/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0522 - accuracy: 0.9825 - val_loss: 0.0951 - val_accuracy: 0.9524\n",
            "Epoch 646/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0532 - accuracy: 0.9825 - val_loss: 0.0578 - val_accuracy: 1.0000\n",
            "Epoch 647/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0583 - accuracy: 0.9825 - val_loss: 0.2783 - val_accuracy: 0.9524\n",
            "Epoch 648/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0605 - accuracy: 0.9737 - val_loss: 0.0934 - val_accuracy: 0.9048\n",
            "Epoch 649/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.6257 - accuracy: 0.9386 - val_loss: 0.4743 - val_accuracy: 0.9048\n",
            "Epoch 650/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6066 - accuracy: 0.7895 - val_loss: 0.5003 - val_accuracy: 0.8095\n",
            "Epoch 651/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.2956 - accuracy: 0.8333 - val_loss: 0.4926 - val_accuracy: 0.6667\n",
            "Epoch 652/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.3892 - accuracy: 0.7632 - val_loss: 0.2444 - val_accuracy: 0.9524\n",
            "Epoch 653/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.2333 - accuracy: 0.8947 - val_loss: 0.2571 - val_accuracy: 0.9048\n",
            "Epoch 654/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.1681 - accuracy: 0.9386 - val_loss: 0.1616 - val_accuracy: 0.9048\n",
            "Epoch 655/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1028 - accuracy: 0.9737 - val_loss: 0.2254 - val_accuracy: 0.9048\n",
            "Epoch 656/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1159 - accuracy: 0.9474 - val_loss: 0.1321 - val_accuracy: 0.9524\n",
            "Epoch 657/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0826 - accuracy: 0.9737 - val_loss: 0.1565 - val_accuracy: 0.9524\n",
            "Epoch 658/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0595 - accuracy: 0.9825 - val_loss: 0.1392 - val_accuracy: 0.9524\n",
            "Epoch 659/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0765 - accuracy: 0.9737 - val_loss: 0.2006 - val_accuracy: 0.9524\n",
            "Epoch 660/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0792 - accuracy: 0.9737 - val_loss: 0.1133 - val_accuracy: 0.9524\n",
            "Epoch 661/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0746 - accuracy: 0.9825 - val_loss: 0.1300 - val_accuracy: 0.9524\n",
            "Epoch 662/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0815 - accuracy: 0.9737 - val_loss: 0.1660 - val_accuracy: 0.9524\n",
            "Epoch 663/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0684 - accuracy: 0.9737 - val_loss: 0.1023 - val_accuracy: 0.9524\n",
            "Epoch 664/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0639 - accuracy: 0.9737 - val_loss: 0.1107 - val_accuracy: 0.9524\n",
            "Epoch 665/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 0.1185 - val_accuracy: 0.9524\n",
            "Epoch 666/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0547 - accuracy: 0.9825 - val_loss: 0.1199 - val_accuracy: 0.9524\n",
            "Epoch 667/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0521 - accuracy: 0.9825 - val_loss: 0.1173 - val_accuracy: 0.9524\n",
            "Epoch 668/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0501 - accuracy: 0.9737 - val_loss: 0.1121 - val_accuracy: 0.9524\n",
            "Epoch 669/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0612 - accuracy: 0.9737 - val_loss: 0.1331 - val_accuracy: 0.9524\n",
            "Epoch 670/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0720 - accuracy: 0.9737 - val_loss: 0.2119 - val_accuracy: 0.9048\n",
            "Epoch 671/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0618 - accuracy: 0.9825 - val_loss: 0.0925 - val_accuracy: 0.9524\n",
            "Epoch 672/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0831 - accuracy: 0.9825 - val_loss: 0.0969 - val_accuracy: 0.9524\n",
            "Epoch 673/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0535 - accuracy: 0.9737 - val_loss: 0.1283 - val_accuracy: 0.9524\n",
            "Epoch 674/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0571 - accuracy: 0.9737 - val_loss: 0.1179 - val_accuracy: 0.9524\n",
            "Epoch 675/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0483 - accuracy: 0.9825 - val_loss: 0.0941 - val_accuracy: 0.9524\n",
            "Epoch 676/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 0.1021 - val_accuracy: 0.9524\n",
            "Epoch 677/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0496 - accuracy: 0.9825 - val_loss: 0.1337 - val_accuracy: 0.9524\n",
            "Epoch 678/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0566 - accuracy: 0.9737 - val_loss: 0.1306 - val_accuracy: 0.9524\n",
            "Epoch 679/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0587 - accuracy: 0.9825 - val_loss: 0.1094 - val_accuracy: 0.9524\n",
            "Epoch 680/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.1281 - val_accuracy: 0.9524\n",
            "Epoch 681/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0529 - accuracy: 0.9737 - val_loss: 0.1124 - val_accuracy: 0.9524\n",
            "Epoch 682/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0469 - accuracy: 0.9825 - val_loss: 0.0913 - val_accuracy: 0.9524\n",
            "Epoch 683/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0571 - accuracy: 0.9737 - val_loss: 0.1193 - val_accuracy: 0.9524\n",
            "Epoch 684/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0495 - accuracy: 0.9737 - val_loss: 0.1033 - val_accuracy: 0.9524\n",
            "Epoch 685/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0512 - accuracy: 0.9737 - val_loss: 0.0993 - val_accuracy: 0.9524\n",
            "Epoch 686/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0717 - accuracy: 0.9737 - val_loss: 0.0928 - val_accuracy: 0.9524\n",
            "Epoch 687/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0805 - accuracy: 0.9649 - val_loss: 0.2393 - val_accuracy: 0.9048\n",
            "Epoch 688/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0589 - accuracy: 0.9737 - val_loss: 0.0777 - val_accuracy: 0.9524\n",
            "Epoch 689/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1091 - accuracy: 0.9649 - val_loss: 0.0781 - val_accuracy: 0.9524\n",
            "Epoch 690/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0546 - accuracy: 0.9737 - val_loss: 0.2509 - val_accuracy: 0.9048\n",
            "Epoch 691/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0862 - accuracy: 0.9737 - val_loss: 0.0927 - val_accuracy: 0.9524\n",
            "Epoch 692/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0678 - accuracy: 0.9825 - val_loss: 0.0926 - val_accuracy: 0.9524\n",
            "Epoch 693/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0717 - accuracy: 0.9825 - val_loss: 0.1115 - val_accuracy: 0.9524\n",
            "Epoch 694/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0588 - accuracy: 0.9737 - val_loss: 0.1518 - val_accuracy: 0.9524\n",
            "Epoch 695/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0639 - accuracy: 0.9737 - val_loss: 0.0896 - val_accuracy: 0.9524\n",
            "Epoch 696/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0548 - accuracy: 0.9825 - val_loss: 0.0965 - val_accuracy: 0.9524\n",
            "Epoch 697/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0501 - accuracy: 0.9737 - val_loss: 0.1158 - val_accuracy: 0.9524\n",
            "Epoch 698/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0454 - accuracy: 0.9912 - val_loss: 0.0936 - val_accuracy: 0.9524\n",
            "Epoch 699/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0586 - accuracy: 0.9825 - val_loss: 0.1027 - val_accuracy: 0.9524\n",
            "Epoch 700/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0552 - accuracy: 0.9737 - val_loss: 0.1823 - val_accuracy: 0.9524\n",
            "Epoch 701/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0619 - accuracy: 0.9737 - val_loss: 0.1114 - val_accuracy: 0.9524\n",
            "Epoch 702/800\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0530 - accuracy: 0.9825 - val_loss: 0.0872 - val_accuracy: 0.9524\n",
            "Epoch 703/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0475 - accuracy: 0.9825 - val_loss: 0.1147 - val_accuracy: 0.9524\n",
            "Epoch 704/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0749 - accuracy: 0.9649 - val_loss: 0.1886 - val_accuracy: 0.9048\n",
            "Epoch 705/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0564 - accuracy: 0.9737 - val_loss: 0.0927 - val_accuracy: 0.9524\n",
            "Epoch 706/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0641 - accuracy: 0.9825 - val_loss: 0.0912 - val_accuracy: 0.9524\n",
            "Epoch 707/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0355 - accuracy: 0.9912 - val_loss: 0.1579 - val_accuracy: 0.9524\n",
            "Epoch 708/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0742 - accuracy: 0.9737 - val_loss: 0.1786 - val_accuracy: 0.9048\n",
            "Epoch 709/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0522 - accuracy: 0.9737 - val_loss: 0.0833 - val_accuracy: 0.9524\n",
            "Epoch 710/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0619 - accuracy: 0.9825 - val_loss: 0.0819 - val_accuracy: 0.9524\n",
            "Epoch 711/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.1315 - val_accuracy: 0.9524\n",
            "Epoch 712/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0619 - accuracy: 0.9737 - val_loss: 0.1970 - val_accuracy: 0.9048\n",
            "Epoch 713/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0529 - accuracy: 0.9737 - val_loss: 0.0923 - val_accuracy: 0.9524\n",
            "Epoch 714/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0424 - accuracy: 0.9825 - val_loss: 0.0738 - val_accuracy: 0.9524\n",
            "Epoch 715/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0813 - accuracy: 0.9737 - val_loss: 0.1685 - val_accuracy: 0.9524\n",
            "Epoch 716/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0713 - accuracy: 0.9737 - val_loss: 0.1647 - val_accuracy: 0.9524\n",
            "Epoch 717/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0579 - accuracy: 0.9825 - val_loss: 0.0755 - val_accuracy: 0.9524\n",
            "Epoch 718/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.9825 - val_loss: 0.0852 - val_accuracy: 0.9524\n",
            "Epoch 719/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 0.1190 - val_accuracy: 0.9524\n",
            "Epoch 720/800\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.1137 - val_accuracy: 0.9524\n",
            "Epoch 721/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0437 - accuracy: 0.9825 - val_loss: 0.0909 - val_accuracy: 0.9524\n",
            "Epoch 722/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0515 - accuracy: 0.9825 - val_loss: 0.0726 - val_accuracy: 0.9524\n",
            "Epoch 723/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.1127 - val_accuracy: 0.9524\n",
            "Epoch 724/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0418 - accuracy: 0.9825 - val_loss: 0.1246 - val_accuracy: 0.9524\n",
            "Epoch 725/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0466 - accuracy: 0.9825 - val_loss: 0.0853 - val_accuracy: 0.9524\n",
            "Epoch 726/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0433 - accuracy: 0.9825 - val_loss: 0.0905 - val_accuracy: 0.9524\n",
            "Epoch 727/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0419 - accuracy: 0.9825 - val_loss: 0.1030 - val_accuracy: 0.9524\n",
            "Epoch 728/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0615 - accuracy: 0.9825 - val_loss: 0.1289 - val_accuracy: 0.9524\n",
            "Epoch 729/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0385 - accuracy: 0.9912 - val_loss: 0.0625 - val_accuracy: 1.0000\n",
            "Epoch 730/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0595 - accuracy: 0.9825 - val_loss: 0.1678 - val_accuracy: 0.9048\n",
            "Epoch 731/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0753 - accuracy: 0.9737 - val_loss: 0.1864 - val_accuracy: 0.9048\n",
            "Epoch 732/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0689 - accuracy: 0.9737 - val_loss: 0.0873 - val_accuracy: 0.9524\n",
            "Epoch 733/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0505 - accuracy: 0.9825 - val_loss: 0.0882 - val_accuracy: 0.9524\n",
            "Epoch 734/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0477 - accuracy: 0.9825 - val_loss: 0.1004 - val_accuracy: 0.9524\n",
            "Epoch 735/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0455 - accuracy: 0.9825 - val_loss: 0.1183 - val_accuracy: 0.9524\n",
            "Epoch 736/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0444 - accuracy: 0.9825 - val_loss: 0.1004 - val_accuracy: 0.9524\n",
            "Epoch 737/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0538 - accuracy: 0.9825 - val_loss: 0.0919 - val_accuracy: 0.9524\n",
            "Epoch 738/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0417 - accuracy: 0.9737 - val_loss: 0.1425 - val_accuracy: 0.9524\n",
            "Epoch 739/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0500 - accuracy: 0.9825 - val_loss: 0.1011 - val_accuracy: 0.9524\n",
            "Epoch 740/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0405 - accuracy: 0.9825 - val_loss: 0.0949 - val_accuracy: 0.9524\n",
            "Epoch 741/800\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.0509 - accuracy: 0.9825 - val_loss: 0.0987 - val_accuracy: 0.9524\n",
            "Epoch 742/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0421 - accuracy: 0.9825 - val_loss: 0.1478 - val_accuracy: 0.9524\n",
            "Epoch 743/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.1030 - val_accuracy: 0.9524\n",
            "Epoch 744/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0401 - accuracy: 0.9825 - val_loss: 0.0823 - val_accuracy: 0.9524\n",
            "Epoch 745/800\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0430 - accuracy: 0.9825 - val_loss: 0.0891 - val_accuracy: 0.9524\n",
            "Epoch 746/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0400 - accuracy: 0.9825 - val_loss: 0.1038 - val_accuracy: 0.9524\n",
            "Epoch 747/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0413 - accuracy: 0.9825 - val_loss: 0.1019 - val_accuracy: 0.9524\n",
            "Epoch 748/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0637 - accuracy: 0.9649 - val_loss: 0.1284 - val_accuracy: 0.9524\n",
            "Epoch 749/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0573 - accuracy: 0.9737 - val_loss: 0.0624 - val_accuracy: 0.9524\n",
            "Epoch 750/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0607 - accuracy: 0.9825 - val_loss: 0.1099 - val_accuracy: 0.9524\n",
            "Epoch 751/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0447 - accuracy: 0.9825 - val_loss: 0.1141 - val_accuracy: 0.9524\n",
            "Epoch 752/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0396 - accuracy: 0.9912 - val_loss: 0.0830 - val_accuracy: 0.9524\n",
            "Epoch 753/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0434 - accuracy: 0.9825 - val_loss: 0.0818 - val_accuracy: 0.9524\n",
            "Epoch 754/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0443 - accuracy: 0.9825 - val_loss: 0.0944 - val_accuracy: 0.9524\n",
            "Epoch 755/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0498 - accuracy: 0.9649 - val_loss: 0.1557 - val_accuracy: 0.9524\n",
            "Epoch 756/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 0.0932 - val_accuracy: 0.9524\n",
            "Epoch 757/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0449 - accuracy: 0.9825 - val_loss: 0.0682 - val_accuracy: 0.9524\n",
            "Epoch 758/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0443 - accuracy: 0.9825 - val_loss: 0.1169 - val_accuracy: 0.9524\n",
            "Epoch 759/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0500 - accuracy: 0.9825 - val_loss: 0.1742 - val_accuracy: 0.9524\n",
            "Epoch 760/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0445 - accuracy: 0.9825 - val_loss: 0.0867 - val_accuracy: 0.9524\n",
            "Epoch 761/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0474 - accuracy: 0.9825 - val_loss: 0.0666 - val_accuracy: 0.9524\n",
            "Epoch 762/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0455 - accuracy: 0.9825 - val_loss: 0.1021 - val_accuracy: 0.9524\n",
            "Epoch 763/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0463 - accuracy: 0.9912 - val_loss: 0.1685 - val_accuracy: 0.9524\n",
            "Epoch 764/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0485 - accuracy: 0.9825 - val_loss: 0.0913 - val_accuracy: 0.9524\n",
            "Epoch 765/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0411 - accuracy: 0.9825 - val_loss: 0.0767 - val_accuracy: 0.9524\n",
            "Epoch 766/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0585 - accuracy: 0.9825 - val_loss: 0.1467 - val_accuracy: 0.9524\n",
            "Epoch 767/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1229 - accuracy: 0.9737 - val_loss: 0.3222 - val_accuracy: 0.9048\n",
            "Epoch 768/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1020 - accuracy: 0.9649 - val_loss: 0.0906 - val_accuracy: 1.0000\n",
            "Epoch 769/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.1204 - accuracy: 0.9474 - val_loss: 0.0916 - val_accuracy: 0.9524\n",
            "Epoch 770/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0575 - accuracy: 0.9825 - val_loss: 0.1983 - val_accuracy: 0.9048\n",
            "Epoch 771/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0866 - accuracy: 0.9737 - val_loss: 0.1754 - val_accuracy: 0.9048\n",
            "Epoch 772/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0619 - accuracy: 0.9825 - val_loss: 0.0945 - val_accuracy: 0.9524\n",
            "Epoch 773/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0568 - accuracy: 0.9825 - val_loss: 0.0825 - val_accuracy: 0.9524\n",
            "Epoch 774/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.1017 - val_accuracy: 0.9524\n",
            "Epoch 775/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0632 - accuracy: 0.9649 - val_loss: 0.1874 - val_accuracy: 0.9048\n",
            "Epoch 776/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0616 - accuracy: 0.9737 - val_loss: 0.1166 - val_accuracy: 0.9524\n",
            "Epoch 777/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 0.0776 - val_accuracy: 0.9524\n",
            "Epoch 778/800\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.0555 - accuracy: 0.9825 - val_loss: 0.1229 - val_accuracy: 0.9524\n",
            "Epoch 779/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0456 - accuracy: 0.9825 - val_loss: 0.1287 - val_accuracy: 0.9524\n",
            "Epoch 780/800\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0438 - accuracy: 0.9912 - val_loss: 0.1000 - val_accuracy: 0.9524\n",
            "Epoch 781/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0434 - accuracy: 0.9825 - val_loss: 0.0897 - val_accuracy: 0.9524\n",
            "Epoch 782/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0428 - accuracy: 0.9825 - val_loss: 0.1065 - val_accuracy: 0.9524\n",
            "Epoch 783/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0460 - accuracy: 0.9912 - val_loss: 0.1292 - val_accuracy: 0.9524\n",
            "Epoch 784/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0444 - accuracy: 0.9825 - val_loss: 0.1094 - val_accuracy: 0.9524\n",
            "Epoch 785/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0426 - accuracy: 0.9825 - val_loss: 0.0674 - val_accuracy: 0.9524\n",
            "Epoch 786/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0473 - accuracy: 0.9825 - val_loss: 0.0939 - val_accuracy: 0.9524\n",
            "Epoch 787/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0413 - accuracy: 0.9825 - val_loss: 0.1205 - val_accuracy: 0.9524\n",
            "Epoch 788/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0419 - accuracy: 0.9912 - val_loss: 0.1115 - val_accuracy: 0.9524\n",
            "Epoch 789/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0405 - accuracy: 0.9912 - val_loss: 0.0971 - val_accuracy: 0.9524\n",
            "Epoch 790/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0404 - accuracy: 0.9825 - val_loss: 0.0835 - val_accuracy: 0.9524\n",
            "Epoch 791/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0454 - accuracy: 0.9825 - val_loss: 0.0837 - val_accuracy: 0.9524\n",
            "Epoch 792/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0414 - accuracy: 0.9825 - val_loss: 0.0986 - val_accuracy: 0.9524\n",
            "Epoch 793/800\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.0437 - accuracy: 0.9825 - val_loss: 0.0869 - val_accuracy: 0.9524\n",
            "Epoch 794/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0387 - accuracy: 0.9825 - val_loss: 0.1025 - val_accuracy: 0.9524\n",
            "Epoch 795/800\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.0413 - accuracy: 0.9825 - val_loss: 0.1103 - val_accuracy: 0.9524\n",
            "Epoch 796/800\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0397 - accuracy: 0.9912 - val_loss: 0.0872 - val_accuracy: 0.9524\n",
            "Epoch 797/800\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.1000 - val_accuracy: 0.9524\n",
            "Epoch 798/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0400 - accuracy: 0.9825 - val_loss: 0.1371 - val_accuracy: 0.9524\n",
            "Epoch 799/800\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.0806 - val_accuracy: 0.9524\n",
            "Epoch 800/800\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.0408 - accuracy: 0.9825 - val_loss: 0.0745 - val_accuracy: 0.9524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssIHu5cM-QOn"
      },
      "source": [
        "#### Plot the learning curves\n",
        "\n",
        "We will now plot two graphs:\n",
        "* Epoch vs accuracy\n",
        "* Epoch vs loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRFBWnUX-QOo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "a64136fc-cc11-4075-f1bf-c07b21754361"
      },
      "source": [
        "#Run this cell to plot the epoch vs accuracy graph\n",
        "\n",
        "try:\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tj0Ir6Sr-QOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "62047678-d4e4-4733-9702-f46f7a77621b"
      },
      "source": [
        "#Run this cell to plot the epoch vs loss graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrsUWJwj-QOr"
      },
      "source": [
        "Oh no! We have overfit our dataset. You should now try to now try to mitigate this overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6N_uo6m-QOs"
      },
      "source": [
        "#### Reducing overfitting in the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGME_x9a-QOs"
      },
      "source": [
        "You should now define a new regularised model.\n",
        "The specs for the regularised model are the same as our original model, with the addition of two dropout layers, weight decay, and a batch normalisation layer. \n",
        "\n",
        "In particular:\n",
        "\n",
        "* Add a dropout layer after the 3rd Dense layer\n",
        "* Then there should be two more Dense layers with 128 units before a batch normalisation layer\n",
        "* Following this, two more Dense layers with 64 units and then another Dropout layer\n",
        "* Two more Dense layers with 64 units and then the final 3-way softmax layer\n",
        "* Add weight decay (l2 kernel regularisation) in all Dense layers except the final softmax layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYytfpmm-QOv"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_regularised_model(input_shape, dropout_rate, weight_decay):\n",
        "    \"\"\"\n",
        "    This function should build a regularised Sequential model according to the above specification. \n",
        "    The dropout_rate argument in the function should be used to set the Dropout rate for all Dropout layers.\n",
        "    L2 kernel regularisation (weight decay) should be added using the weight_decay argument to \n",
        "    set the weight decay coefficient in all Dense layers that use L2 regularisation.\n",
        "    Ensure the weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument input_shape.\n",
        "    Your function should return the model.\n",
        "    \"\"\"\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw79AOPy-QOx"
      },
      "source": [
        "#### Instantiate, compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO8JYVXB-QOz"
      },
      "source": [
        "# Instantiate the model, using a dropout rate of 0.3 and weight decay coefficient of 0.001\n",
        "\n",
        "reg_model = get_regularised_model(train_data[0].shape, 0.3, 0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOEqCQ3I-QO2"
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "compile_model(reg_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eg83stX-QO6"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "reg_history = train_model(reg_model, train_data, train_targets, epochs=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gccWcGCz-QO8"
      },
      "source": [
        "#### Plot the learning curves\n",
        "\n",
        "Let's now plot the loss and accuracy for the training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8uieP3K-QO9"
      },
      "source": [
        "#Run this cell to plot the new accuracy vs epoch graph\n",
        "\n",
        "try:\n",
        "    plt.plot(reg_history.history['accuracy'])\n",
        "    plt.plot(reg_history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(reg_history.history['acc'])\n",
        "    plt.plot(reg_history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpgy4mVP-QO_"
      },
      "source": [
        "#Run this cell to plot the new loss vs epoch graph\n",
        "\n",
        "plt.plot(reg_history.history['loss'])\n",
        "plt.plot(reg_history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na0xiTpm-QPB"
      },
      "source": [
        "We can see that the regularisation has helped to reduce the overfitting of the network.\n",
        "You will now incorporate callbacks into a new training run that implements early stopping and learning rate reduction on plateaux.\n",
        "\n",
        "Fill in the function below so that:\n",
        "\n",
        "* It creates an `EarlyStopping` callback object and a `ReduceLROnPlateau` callback object\n",
        "* The early stopping callback is used and monitors validation loss with the mode set to `\"min\"` and patience of 30.\n",
        "* The learning rate reduction on plateaux is used with a learning rate factor of 0.2 and a patience of 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18JaoKcd-QPC"
      },
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function. \n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_callbacks():\n",
        "    \"\"\"\n",
        "    This function should create and return a tuple (early_stopping, learning_rate_reduction) callbacks.\n",
        "    The callbacks should be instantiated according to the above requirements.\n",
        "    \"\"\"\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqi6pF-v-QPD"
      },
      "source": [
        "Run the cell below to instantiate and train the regularised model with the callbacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emW-CYSd-QPE"
      },
      "source": [
        "call_model = get_regularised_model(train_data[0].shape, 0.3, 0.0001)\n",
        "compile_model(call_model)\n",
        "early_stopping, learning_rate_reduction = get_callbacks()\n",
        "call_history = call_model.fit(train_data, train_targets, epochs=800, validation_split=0.15,\n",
        "                         callbacks=[early_stopping, learning_rate_reduction], verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtuDazML-QPG"
      },
      "source": [
        "learning_rate_reduction.patience"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zhsqvtL-QPJ"
      },
      "source": [
        "Finally, let's replot the accuracy and loss graphs for our new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOPSJT7w-QPJ"
      },
      "source": [
        "try:\n",
        "    plt.plot(call_history.history['accuracy'])\n",
        "    plt.plot(call_history.history['val_accuracy'])\n",
        "except KeyError:\n",
        "    plt.plot(call_history.history['acc'])\n",
        "    plt.plot(call_history.history['val_acc'])\n",
        "plt.title('Accuracy vs. epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w5NOgER-QPL"
      },
      "source": [
        "plt.plot(call_history.history['loss'])\n",
        "plt.plot(call_history.history['val_loss'])\n",
        "plt.title('Loss vs. epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper right')\n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsBmI_qM5CYh"
      },
      "source": [
        "# Evaluate the model on the test set\n",
        "\n",
        "test_loss, test_acc = call_model.evaluate(test_data, test_targets, verbose=0)\n",
        "print(\"Test loss: {:.3f}\\nTest accuracy: {:.2f}%\".format(test_loss, 100 * test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqBMocM0-QPM"
      },
      "source": [
        "Congratulations for completing this programming assignment! In the next week of the course we will learn how to save and load pre-trained models."
      ]
    }
  ]
}